{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2deaf054",
   "metadata": {},
   "source": [
    "# This file has the sole purpose of conducting tests for the negotiation model between pedestrians.\n",
    "\n",
    "### A first objective is to test and develop a negotiation model based on social choice theory, regardless of the motion part\n",
    "\n",
    "The conducted tests will mainly use Mesa, a Python library developed to work with agent-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50df72-1a9b-4d5d-9686-a6044bfffd4f",
   "metadata": {},
   "source": [
    "# Social model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661f579-3095-44c9-98c4-4819499f5a9d",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "ffee672a-f3a8-41ce-84e9-4faff2ee1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.15 (main, Sep  7 2024, 00:20:06) [Clang 15.0.0 (clang-1500.3.9.4)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "f5f35b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa # version 3.0.0a4\n",
    "\n",
    "# Data visualization tools.\n",
    "import seaborn as sns\n",
    "\n",
    "# Has multi-dimensional arrays and matrices. Has a large collection of\n",
    "# mathematical functions to operate on these arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Data manipulation and analysis.\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "# Path finding\n",
    "# @ https://www.youtube.com/watch?v=8SigT_jhz4I\n",
    "from pathfinding.core.grid import Grid\n",
    "from pathfinding.finder.a_star import AStarFinder\n",
    "from pathfinding.core.diagonal_movement import DiagonalMovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f8edc247-019a-4f4e-a338-ebb28bcca030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 0, 0, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [0, 0, 0, 0, 1], [1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "map1 = [[0,0,2,2,0],\n",
    "        [1,0,0,0,1],\n",
    "        [0,0,0,0,0],\n",
    "        [2,2,2,2,0],\n",
    "        [0,0,3,0,0]]\n",
    "\n",
    "map2 = [[0,0,0,2,0,0,1],\n",
    "        [0,0,0,0,2,2,0],\n",
    "        [0,0,2,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0],\n",
    "        [0,0,2,0,2,2,0],\n",
    "        [0,0,2,0,2,0,0],\n",
    "        [3,0,2,2,0,0,1]    \n",
    "       ]\n",
    "\n",
    "map3 =  [[0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 2, 2, 0, 0, 0, 1],\n",
    "         [0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 2, 2, 0, 0, 0, 0, 0],\n",
    "         [3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 2, 0, 0, 0, 1],\n",
    "         [0, 0, 0, 0, 0, 2, 2, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 2, 2, 0, 0, 0, 0],\n",
    "        ]\n",
    "\n",
    "map4 = [\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1],\n",
    " [0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "map5 = [\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 2, 0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "map6 = [\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 0],\n",
    "    [0, 1, 0, 2, 0, 0, 2, 0, 1, 0],\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [3, 1, 0, 0, 0, 0, 0, 0, 1, 3],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 2, 0, 0, 2, 0, 1, 0],\n",
    "    [0, 1, 0, 2, 0, 0, 2, 0, 1, 0],\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 0],\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 0]\n",
    "]\n",
    "\n",
    "map7 = [ [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0],\n",
    "  [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0],\n",
    "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0],\n",
    "  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "  [3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3],\n",
    "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
    "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0],\n",
    "  [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]\n",
    "]\n",
    "\n",
    "map8 = [\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [3, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 3],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "maps = [map1, map2, map3, map4, map5, map6, map7, map8]\n",
    "\n",
    "def transform_grid(card):\n",
    "    \"\"\"\n",
    "        Short utility function to only consider free (1) and obstacles (0) in the map.\n",
    "        Used to collaborate with the pathfinding library.\n",
    "    \"\"\"\n",
    "    new_map = []\n",
    "    for row in card:\n",
    "        new_col = []\n",
    "        for col in row:\n",
    "            if col == 2: # Obstacle\n",
    "                new_col.append(0)\n",
    "            else:\n",
    "                new_col.append(1)\n",
    "        new_map.append(new_col)\n",
    "    return new_map\n",
    "\n",
    "print(transform_grid(map1))\n",
    "\n",
    "def convert_coords(pos):\n",
    "    \"\"\"\n",
    "        Convert real coordinates to integer coordinates.\n",
    "    \"\"\"\n",
    "    return (round(pos[0]), round(pos[1]))\n",
    "\n",
    "def is_walkable(grid, position, unique_id):\n",
    "    pos = position\n",
    "    for a in grid.get_neighbors(pos, .1, True):\n",
    "        if a.unique_id != unique_id and not isinstance(a, Objective):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def collides(path1, path2):\n",
    "    if len(path2) < len(path1):\n",
    "        path1, path2 = path2, path1\n",
    "    # Bias of collision: the crossing is considered more important as an imminent collision\n",
    "    if len(path1) > 1: # Bias of selection: the shortest path is considered with the colliding point, i.e., the agent with the longest path is the obstacle\n",
    "        # Crossing paths\n",
    "        if path1[1][0] == path2[0][0] and path1[1][1] == path2[0][1]:\n",
    "            return (path2[0][0], path2[0][1])\n",
    "    # Common path\n",
    "    for i in range(len(path1)-1):\n",
    "        p1 = path1[i]\n",
    "        p2 = path2[i]\n",
    "        if p1[0] == p2[0] and p1[1] == p2[1]:\n",
    "            return (p1[0], p1[1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "294b4fe1-14b4-40d9-9b54-bd07950ab48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 1]\n",
      "Found path:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapp = transform_grid(map1[::-1])\n",
    "for r in mapp:\n",
    "    print(r)\n",
    "grid = Grid(height=5, width=5, matrix = mapp, inverse=False, grid_id=1)\n",
    "\n",
    "grid_self_pos = (0, 1)\n",
    "\n",
    "start = grid.node(grid_self_pos[0], grid_self_pos[1])\n",
    "end = grid.node(2,4)\n",
    "\n",
    "finder = AStarFinder(diagonal_movement = DiagonalMovement.always)\n",
    "path, runs = finder.find_path(start, end, grid)\n",
    "\n",
    "print(\"Found path:\")\n",
    "for p in path:\n",
    "    print((p.x, p.y), end='; ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcc9e0-bf19-4311-b79a-d8debe354bb5",
   "metadata": {},
   "source": [
    "### A first jet on preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "3f79e9be-2c33-478f-922f-4e35540a6740",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'goal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[453], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcost of agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[453], line 13\u001b[0m, in \u001b[0;36mcost\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     11\u001b[0m pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(positions[agent])\n\u001b[1;32m     12\u001b[0m objective \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(goals[agent])\n\u001b[0;32m---> 13\u001b[0m dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(pos\u001b[38;5;241m-\u001b[39m\u001b[43mgoal\u001b[49m)\n\u001b[1;32m     14\u001b[0m size \u001b[38;5;241m=\u001b[39m trajectories[agent]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdist of agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'goal' is not defined"
     ]
    }
   ],
   "source": [
    "# Give two virtual agents their features.\n",
    "motivations = [.5, .5]\n",
    "objectives = [(5,5), (-2, -3)]\n",
    "positions = [(0, 0), (3,4)]\n",
    "trajectories = [6, 4] # paths sizes\n",
    "speed = [2.4, 1.8] # m/s\n",
    "\n",
    "# Let the first proposed cost function be defined, given K1=K2=K3=1\n",
    "def cost(agent):\n",
    "    mot = motivations[agent]\n",
    "    pos = np.array(positions[agent])\n",
    "    objective = np.array(goals[agent])\n",
    "    dist = np.linalg.norm(pos-goal)\n",
    "    size = trajectories[agent]\n",
    "    print(f\"dist of agent {agent}: {dist}\")\n",
    "    return round((4 * size) / dist + speed[agent] + (1 / mot), 3)\n",
    "\n",
    "# Same function adapted for the model below.\n",
    "def path_cost(agent, path):\n",
    "    mot = agent.motivation\n",
    "    pos = agent.position\n",
    "    goal = agent.objective\n",
    "    speed = agent.speed\n",
    "    dist = agent.model.grid.get_distance(pos, goal)\n",
    "    size = len(path)\n",
    "    if dist <= 0:\n",
    "        return -1\n",
    "    return round((2 * size) / dist + speed + (1 / mot), 3)\n",
    "\n",
    "def estimate_trajectory(direction):\n",
    "    \"\"\"\n",
    "        This current trajectory estimation is done through linear approximation.\n",
    "    \"\"\"\n",
    "    dx, dy = direction\n",
    "    pass\n",
    "\n",
    "for agent in range(2):\n",
    "    print(f\"cost of agent {agent}: {cost(agent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddf017",
   "metadata": {},
   "source": [
    "## Agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f0624f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ped(mesa.Agent):\n",
    "    \n",
    "    def __init__(self, model, pos):\n",
    "        super().__init__(model)\n",
    "\n",
    "        # If the agent still didn't reach its objective\n",
    "        self.active = True\n",
    "\n",
    "        # Traits\n",
    "        self.motivation = min(.3, np.random.rand()) # 0.3-1\n",
    "        self.speed = np.random.rand() + 1\n",
    "        self.satisfaction = np.random.uniform(-3, 1) # Satisfaction threshold of the current situation the agent is in.\n",
    "        # The lower the satisfaction the more an agent can acclimate to the others.\n",
    "\n",
    "        self.position = pos\n",
    "        self.direction = None\n",
    "        self.alert = False\n",
    "        self.wait = False\n",
    "        self.path = None\n",
    "        self.negotiating = False\n",
    "        self.current_cost = -1\n",
    "        self.alternatives = {}\n",
    "        self.influenced = False\n",
    "    \n",
    "    def set_objective(self, obj):\n",
    "        self.objective_obj = obj\n",
    "        self.objective = obj.position\n",
    "\n",
    "    def find_path(self, obstacles=None, diag=True):\n",
    "        #TODO add current positions as obstacles\n",
    "        grid = None\n",
    "        if obstacles is None:\n",
    "            grid = Grid(height=len(self.model.card), width=len(self.model.card[0]), matrix = self.model.card, inverse=False, grid_id=1)\n",
    "        else:\n",
    "            matrix = copy.deepcopy(self.model.card)\n",
    "            for obstacle in obstacles:\n",
    "                x, y = obstacle\n",
    "                matrix[y][x] = 0\n",
    "            grid = Grid(height=len(self.model.card), width=len(self.model.card[0]), matrix = matrix, inverse=False, grid_id=2)\n",
    "        \n",
    "        grid_self_pos = convert_coords(self.position)\n",
    "\n",
    "        start = grid.node(grid_self_pos[0], grid_self_pos[1])\n",
    "        end = grid.node(self.objective[0], self.objective[1])\n",
    "\n",
    "        finder = AStarFinder(diagonal_movement = DiagonalMovement.always if diag else DiagonalMovement.never)\n",
    "        path, runs = finder.find_path(start, end, grid)\n",
    "\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        path = list(map(cell, path))\n",
    "        return None if len(path) == 0 else tuple(path) # Convert the paths to a tuple of pairs as it is hashable.\n",
    "\n",
    "    def get_direction(self):\n",
    "        if self.path is not None and len(self.path) > 1:\n",
    "            end = np.array((self.path[1][0], self.path[1][1]))\n",
    "            start = np.array((self.position[0], self.position[1]))\n",
    "            data = end - start\n",
    "\n",
    "            if not (data == 0).all():\n",
    "                data = data / np.linalg.norm(data)\n",
    "            \n",
    "            def round_to_half_unit(n):\n",
    "                return round(n * 2) / 2\n",
    "            \n",
    "            self.direction = list(map(round, data))\n",
    "            # self.model.log(f\"{self.unique_id} changed direction.\")\n",
    "            # self.model.log(f\"{self.unique_id}'s current path: {self.path}\")\n",
    "    \n",
    "    \"\"\"\n",
    "        Self utility function to consider a proposed path with its associated cost.\n",
    "        If the current agent finds the proposition considerable, relative to its satisfaction and the proposed cost,\n",
    "        then it reconsiders the best suitable alternative (collision-free) by re-evaluating its associated cost (diminish it).\n",
    "    \"\"\"\n",
    "    def consider_alternative(self, path, cost):\n",
    "        # Sort alternatives in ascending cost order, for now the agents want to avoid collision\n",
    "        if len(self.alternatives) <= 0:\n",
    "            self.compute_set()\n",
    "            if len(self.alternatives) <= 0: # Blocked agent\n",
    "                return False\n",
    "            \n",
    "        alts = sorted(self.alternatives, key=self.alternatives.get)\n",
    "        # Get the first collision-free alternative\n",
    "        best_alt = None\n",
    "        for alt in alts:\n",
    "            if collides(alt, path) is None: # Found one\n",
    "                best_alt = alt\n",
    "                break\n",
    "        # If a CF-trajectory was not found, find a potential alternative\n",
    "        best_alt_2 = None\n",
    "        if best_alt is None:\n",
    "            # We didn't find an alternative, compute one\n",
    "            self.colliding_point = collides(alts[0], path)\n",
    "            colliding_points = [self.colliding_point]\n",
    "            for neigh in self.model.grid.get_neighbors(self.position, 2, False):\n",
    "                if isinstance(neigh, Ped) and neigh.active:\n",
    "                    colliding_points.append(neigh.position)\n",
    "            best_alt = self.find_path(obstacles = colliding_points) # Compute a new CF trajectory (part of the recompute actually)\n",
    "            best_alt_2 = self.find_path(obstacles = colliding_points, diag=False)\n",
    "\n",
    "            if best_alt is None and best_alt_2 is None: # If not found, get the best possible alternative w.r.t. the given cost\n",
    "                self.model.log(f\"{self.unique_id} didn't find a collision-free path, best alternative.\")\n",
    "                best_alts = list(filter(lambda p: self.alternatives[p] - self.motivation <= cost, alts))\n",
    "                if len(best_alts) > 0:\n",
    "                    best_alt = min(best_alts)\n",
    "            \n",
    "            # Save alternative if valid\n",
    "            no_alt = True\n",
    "            if best_alt is not None:\n",
    "                self.add_alternative(best_alt)\n",
    "                no_alt = False\n",
    "            if best_alt_2 is not None:\n",
    "                self.add_alternative(best_alt_2)\n",
    "                no_alt = False\n",
    "            if no_alt:\n",
    "                self.model.log(f\"{self.unique_id} had no alternative.\")\n",
    "                return False\n",
    "        \n",
    "        if best_alt == self.path or best_alt_2 == self.path: # If the considered path is the same we considered, ignore.\n",
    "            self.model.log(f\"{self.unique_id} was already planning on to take this alternative.\")\n",
    "            return True\n",
    "        \n",
    "        if best_alt_2 is not None:\n",
    "            best_alt = min([best_alt, best_alt_2], key=self.alternatives.get)\n",
    "\n",
    "        # Compute the value of worthiness to take this alternative compared to the envisioned cost of the other's\n",
    "        value = cost - self.alternatives[best_alt]\n",
    "        self.model.log(f\"An influence happened: {self.unique_id} processes a change of value {value}.\")\n",
    "        if value > self.motivation: # If the agent is satisfied with this alternative, it takes it. The cost should change.\n",
    "            self.model.log(f\"> {self.unique_id} reconsiders an alternative.\")\n",
    "            #self.alternatives[best_alt] = self.alternatives[min(self.alternatives, key=self.alternatives.get)] # We consider a cost similar to its best alternative as a measure of consideration.\n",
    "            self.alternatives[best_alt] = max(0, self.alternatives[best_alt] - min(abs(value), 3)) # The motivation may represent a cost adaptation to the others' offers, the less we win negotiations, the less we want to adapt ourselves\n",
    "            self.model.log(f\"{self.unique_id}'s alternatives: {self.alternatives}\")\n",
    "            new_path = self.select_path()\n",
    "            if new_path is not None and new_path != self.path:\n",
    "                self.model.log(f\"> {self.unique_id} takes another alternative.\")\n",
    "                self.path = new_path\n",
    "            self.influenced = True\n",
    "            return True\n",
    "        \n",
    "        self.model.log(f\"> {self.unique_id} agent refused the alternative.\")\n",
    "        # Otherwise the agent did not consider it\n",
    "        return False\n",
    "    \n",
    "    def select_path(self):\n",
    "        \"\"\"\n",
    "            Cognition part\n",
    "        \"\"\"\n",
    "        if len(self.alternatives) > 0:\n",
    "            bests = sorted(self.alternatives, key=self.alternatives.get)\n",
    "            best = bests[0]\n",
    "            #collision_free = list(filter(lambda p: is_walkable(self.model.grid, p[1], self.unique_id), bests))\n",
    "            #if len(collision_free) > 0:\n",
    "            #    best = min(collision_free)\n",
    "            #self.model.log(f\"{self.unique_id} has {len(self.alternatives)} alternatives: selected one with cost {self.alternatives[best]}\")\n",
    "            #self.model.log(f\"Alternatives of {self.unique_id}: {self.alternatives}\")\n",
    "            return best\n",
    "        return None\n",
    "    \n",
    "    def compute_set(self, obstacles=None):\n",
    "        \"\"\"\n",
    "            To enrich\n",
    "        \"\"\"\n",
    "        # TBR\n",
    "        path = self.find_path(obstacles=obstacles)\n",
    "        #path_wait = (convert_coords(self.position),) + self.find_path(obstacles=obstacles)\n",
    "        #self.model.log(f\"{self.unique_id}'s path cost: {path_cost(self, path)}\")\n",
    "        #self.model.log(f\"{self.unique_id}'s path_wait cost: {path_cost(self, path_wait)}\")\n",
    "        if path is not None:\n",
    "            self.add_alternative(path)\n",
    "        #if path_wait is not None:\n",
    "            #self.add_alternative(path_wait)\n",
    "\n",
    "    def clear_set(self):\n",
    "        self.alternatives = {}\n",
    "    \n",
    "    def negotiate(self, neigh):\n",
    "        self.negotiating = True\n",
    "        self.colliding_point = collides(self.path, neigh.path)\n",
    "        if self.colliding_point is not None:\n",
    "            self.alert = True\n",
    "            self.bargainer = neigh\n",
    "            match self.model.params[\"negotiation\"]:\n",
    "                case \"wait_only\":\n",
    "                    if path_cost(self, self.path) < path_cost(self.bargainer, self.bargainer.path):\n",
    "                        self.wait = True\n",
    "                    self.bargainer.current_cost = path_cost(self.bargainer, self.bargainer.path)\n",
    "                    self.current_cost = path_cost(self, self.path)\n",
    "                case \"alt_or_wait\":\n",
    "                    alt_path = self.find_path(obstacles = [self.colliding_point], diag = True)\n",
    "                    alt_pathneigh = self.bargainer.find_path(obstacles = [self.colliding_point], diag = True)\n",
    "                    if alt_path is None or alt_pathneigh is None:\n",
    "                        if path_cost(self, self.path) > path_cost(self.bargainer, self.bargainer.path):\n",
    "                            self.wait = True\n",
    "                        else:\n",
    "                            self.bargainer.wait = True\n",
    "                    elif path_cost(self, alt_path) > path_cost(self.bargainer, alt_pathneigh):\n",
    "                        self.bargainer.path = alt_pathneigh\n",
    "                        self.bargainer.get_direction()\n",
    "                    else:\n",
    "                        self.path = alt_path\n",
    "                        self.get_direction() # update direction!!\n",
    "                    #TODO à mettre à jour\n",
    "                    self.current_cost = path_cost(self, alt_path)\n",
    "                    self.bargainer.current_cost = path_cost(self.bargainer, alt_pathneigh)\n",
    "\n",
    "    def add_alternative(self, path):\n",
    "        #self.model.log(f\"{self.unique_id}'s added path with cost: {path_cost(self, path)}\")\n",
    "        self.alternatives[path] = path_cost(self, path)\n",
    "\n",
    "    def init(self):\n",
    "        # First cognition step, to show trajectories.\n",
    "        self.compute_set()\n",
    "        self.path = self.select_path()\n",
    "        self.get_direction()\n",
    "    \n",
    "    def get_next_position(self):\n",
    "        \"\"\"\n",
    "            @returns: The next position given by the direction.\n",
    "        \"\"\"\n",
    "        return (self.position[0] + self.direction[0], self.position[1] + self.direction[1])\n",
    "    \n",
    "    def move(self, position):\n",
    "        \"\"\"\n",
    "            Attempt to move self to the given position.\n",
    "            \n",
    "            @returns: True if it moved, False otherwise\n",
    "        \"\"\"\n",
    "        if is_walkable(self.model.grid, position, self.unique_id):\n",
    "            self.position = position\n",
    "            self.model.grid.move_agent(self, self.position)\n",
    "            self.path = self.path[1:]\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def step(self):\n",
    "        if not self.active:\n",
    "            return\n",
    "        \n",
    "        # Reset (in order)\n",
    "        self.negotiating = False\n",
    "        self.alert = False\n",
    "        self.colliding_point = None\n",
    "        self.influenced = False\n",
    "\n",
    "        # Cognition is supposed to be before motion, in order, however the initialisation step takes care of it.\n",
    "        \n",
    "        ### Move agent\n",
    "        \n",
    "        #self.position = (self.position[0] + .2, self.position[1] + .2)\n",
    "        alt = False\n",
    "        if not self.wait:\n",
    "            moved = False\n",
    "            position = self.get_next_position()\n",
    "            if self.direction is not None:\n",
    "                ## Check collision\n",
    "                moved = self.move(position)\n",
    "            # Otherwise wait or re-engage: to be discussed\n",
    "            # if an agent cannot move forward it is probably because there is some congestion, a negotiation process is quite meaningless here. Consider own alternative trajectory.\n",
    "            #\n",
    "            # This step is very important to discuss. In fact, the motion happens before the cognition part because of the initialization.\n",
    "            # As such, if the agent considers another alternative then it triggers the cognition part in advance and then moves. In order to respect the execution order the agent has to recompute its direction\n",
    "            # one more time to ensure the next move.\n",
    "            if not moved and not self.influenced:\n",
    "                self.model.log(f\"{self.unique_id} is blocked and not under influence, it considers another alternative.\")\n",
    "                mode = \"do_nothing\" # reflex?\n",
    "                match mode:\n",
    "                    case \"instant_alternative\":\n",
    "                        colliding_points = [position]\n",
    "                        for neigh in self.model.grid.get_neighbors(self.position, 2, False):\n",
    "                            if isinstance(neigh, Ped) and neigh.active:\n",
    "                                colliding_points.append(neigh.position)\n",
    "                        \n",
    "                        self.compute_set(obstacles=colliding_points)\n",
    "                        path = self.select_path()\n",
    "                        if path is not None:\n",
    "                            self.path = path\n",
    "                            self.get_direction()\n",
    "                            position = self.get_next_position()\n",
    "                            self.move(position)\n",
    "                            self.get_direction()\n",
    "                            alt = True\n",
    "                    #case _:\n",
    "                        # Wait by default\n",
    "        #else:\n",
    "            # Waiting is in trajectory\n",
    "            #self.path = self.path[1:]\n",
    "                        \n",
    "        \n",
    "        if self.position == self.objective:\n",
    "            self.active = False\n",
    "            self.model.grid.remove_agent(self)\n",
    "            return\n",
    "        \n",
    "        ### Cognition\n",
    "        match self.model.params[\"model\"]:\n",
    "            case \"first\":\n",
    "                self.compute_set()\n",
    "                self.path = self.select_path()\n",
    "                self.get_direction()\n",
    "            case \"second\":\n",
    "                self.clear_set() # is it fixed to compute_set? maybe\n",
    "                self.compute_set()\n",
    "                if not alt and not self.influenced:\n",
    "                    self.path = self.select_path()\n",
    "                    self.get_direction()\n",
    "\n",
    "        # Reset\n",
    "        self.wait = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb93385e-bebe-484a-804c-b689b6a963dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obstacle(mesa.Agent):\n",
    "    \n",
    "    def __init__(self, model, pos):\n",
    "        super().__init__(model)\n",
    "        self.position = pos\n",
    "\n",
    "    def step(self):\n",
    "        pass\n",
    "\n",
    "class Objective(mesa.Agent):\n",
    "    \n",
    "    def __init__(self, model, pos, id):\n",
    "        super().__init__(model)\n",
    "        self.position = pos\n",
    "        self.id = id\n",
    "\n",
    "    def step(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96cb69",
   "metadata": {},
   "source": [
    "## Global model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4543a3b-4b65-421a-b107-3c897787fa27",
   "metadata": {},
   "source": [
    "### Negotiation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fff84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negotiation():\n",
    "    \"\"\"\n",
    "        A negotiation process happens between at least two agents, for now, in case of a collision.\n",
    "        A negotiation is the influence of a1 towards a2, a1 is trying to change the a2's preferences, with possible failure.\n",
    "\n",
    "        The following negotiation will happen:\n",
    "            a1 --->(influences) a2\n",
    "    \"\"\"\n",
    "    def __init__(self, model, a1, a2):\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "        self.model = model\n",
    "\n",
    "    \"\"\"\n",
    "        The negotiation process starts here, the result of such a process results in a failure for a1 or not.\n",
    "\n",
    "        @returns: False if a1 didn't suceed in its bargaining, True otherwise.\n",
    "    \"\"\"\n",
    "    def start(self):\n",
    "        result = False # No success for negotiation at beginning.\n",
    "\n",
    "        # Option\n",
    "        mode = \"self_trajectory\" # to change to self.model.params[\"influence_mode\"]\n",
    "\n",
    "        match mode:\n",
    "            case \"self_trajectory\":\n",
    "                \"\"\"\n",
    "                    This mode describes a1's influence as the proposal of its trajectory as an influence towards a2.\n",
    "                    a1's trajectory (i.e., path) is communicated along its cost to reveal (do we consider dishonesty?) its willingness/unwillingness to change path.\n",
    "                    a2 can then choose to either re-evaluate its best alternative collision-free trajectory's (w.r.t to a1's proposed path) cost, if it considers it worth it\n",
    "                    according to its tolerance threshold/motivation.\n",
    "                \"\"\"\n",
    "                a1 = self.a1\n",
    "                a2 = self.a2\n",
    "                # a1 proposes its trajectory to a2\n",
    "                ## a2 evaluates it and computes an alternative w.r.t. its threshold\n",
    "                self.model.log(f\"{a1.unique_id} negotiates with {a2.unique_id}\")\n",
    "                considered = a2.consider_alternative(a1.path, path_cost(a1, a1.path)) # TBI\n",
    "                if considered:\n",
    "                    a2.get_direction()\n",
    "                return considered\n",
    "            case _:\n",
    "                self.model.log(\"[Error] Unknown influence method. Abort influence.\")\n",
    "                return False\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ea887",
   "metadata": {},
   "source": [
    "### Vote process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "99f0b9ea-a37e-4f55-a01b-dca00108ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vote():\n",
    "    def __init__(self, model, agents):\n",
    "        self.model = model\n",
    "        self.neg_schedule = mesa.time.RandomActivation(self)\n",
    "        for a in agents:\n",
    "            self.neg_schedule.add(a)\n",
    "        self.step = 0\n",
    "        self.Gamma = 5 # Option\n",
    "        self.conflicts = []\n",
    "    \n",
    "    def start(self):\n",
    "        self.model.log(\"------- Vote started -------\")\n",
    "        while self.step < self.Gamma:\n",
    "            self.model.log(f\"--- Iteration {self.step} ---\")\n",
    "            if not self.iter():\n",
    "                self.model.log(\"The vote ended prematurely, as there was no collision.\")\n",
    "                self.model.log(\"------- Vote ended -------\")# Clear alternatives\n",
    "                for a in self.neg_schedule.agents:\n",
    "                    a.clear_set()\n",
    "                return\n",
    "        # Check collisions\n",
    "        for conflict in self.conflicts:\n",
    "            # If there remain *IMMINENT* collisions then wait for some agents\n",
    "            a, neigh = conflict\n",
    "            # sort speed??\n",
    "            # in truth, the colliding point may be updated even if paths were not updated, so it should be saved before\n",
    "            colliding_point = collides(a.path, neigh.path)\n",
    "            if len(a.path) > 1 and is_walkable(self.model.grid, a.path[1], a.unique_id) and a.path[1] != colliding_point:\n",
    "                continue\n",
    "            if len(neigh.path) > 1 and is_walkable(self.model.grid, neigh.path[1], neigh.unique_id) and neigh.path[1] != colliding_point:\n",
    "                continue\n",
    "            # Otherwise, imminent collision, wait for the one that has the most motivation\n",
    "            if a.motivation > neigh.motivation:\n",
    "                self.model.log(f\"> {a.unique_id} waited as negotiations didn't conclude.\")\n",
    "                a.wait = True\n",
    "            else:\n",
    "                self.model.log(f\"> {neigh.unique_id} waited as negotiations didn't conclude.\")\n",
    "                neigh.wait = True\n",
    "        # Clear alternatives and end negotiations\n",
    "        for a in self.neg_schedule.agents:\n",
    "            a.clear_set()\n",
    "        self.model.log(\"------- Vote ended -------\")\n",
    "    \n",
    "    def compute_welfare(self, collisions):\n",
    "        # Option\n",
    "        # param: mean\n",
    "        welfare = 0\n",
    "        for c in collisions:\n",
    "            a, neigh = c\n",
    "            welfare += abs(path_cost(a, a.path) - path_cost(neigh, neigh.path))\n",
    "        welfare /= len(collisions)\n",
    "        return welfare\n",
    "\n",
    "    def iter(self):\n",
    "\n",
    "        # I. Vote\n",
    "        # For now, each agent proposes its trajectory as its vote. If there is a collision, then negotiations continue.\n",
    "        ## To check on litterature\n",
    "        self.conflicts = [] # Pairs of agents that have conflicts between their respective paths\n",
    "        no_conflicts = []\n",
    "        DELTA = 2\n",
    "        # is it truly shuffled without iter?\n",
    "        for a in self.neg_schedule.agents:\n",
    "           for neigh in self.model.grid.get_neighbors(a.position, DELTA, False):\n",
    "                if isinstance(neigh, Ped) and neigh.active and not neigh.alert:\n",
    "                    if neigh.unique_id != a.unique_id:\n",
    "                        if collides(a.path, neigh.path) and (a, neigh) not in self.conflicts and (neigh, a) not in self.conflicts:\n",
    "                            self.model.log(f\"Conflict between {a.unique_id} and {neigh.unique_id}\")\n",
    "                            self.conflicts.append((a, neigh))\n",
    "                        else:\n",
    "                            no_conflicts.append((a, neigh))\n",
    "\n",
    "        ## If there is no conflict between agents, then negotiation ends.\n",
    "        # Option: This should be parameterized as agents may want to negotiate better trajectories even though there is no collision.\n",
    "        if self.conflicts == []:\n",
    "            self.model.log(\"No conflict\")\n",
    "            return False # End vote\n",
    "        \n",
    "        ## Compute welfare, all agents can get to know the welfare.\n",
    "        self.model.welfare = self.compute_welfare(self.conflicts)\n",
    "\n",
    "        # II. Influences\n",
    "        gain = .2 # Option\n",
    "        ## The agents influence themselves, e.g., try to impose their trajectory to others in order to change costs or votes.\n",
    "        for conflict in self.conflicts:\n",
    "            a, neigh = conflict\n",
    "            # Option: even if the agent is satisfied with the global welfare, if there remains a collision he can influence the other to take an advantaging trajectory for it.\n",
    "            # Satisfaction alone seems too independent and not relevant alone. We should consider satisfaction computed through the preferences to consider the relevancy of negotiations or not.\n",
    "            # The motivation is also considered through the cost function. Is it really different?\n",
    "            # In any case agents, here, should negotiate if there is a collision regardless of their satisfaction (reality constraint).\n",
    "            #if a.satisfaction < self.model.welfare:\n",
    "            # The satisfaction parameter should then play in collision-free trajectory agents.\n",
    "            a.negotiating = True\n",
    "            neigh.negotiating = True\n",
    "            success1 = Negotiation(self.model, a, neigh).start()\n",
    "            if not success1 and a.motivation - gain <= 0:\n",
    "                a.motivation /= 2\n",
    "            else:\n",
    "                a.motivation += gain if success1 else -gain\n",
    "            #a.motivation = max(.000001, a.motivation)\n",
    "\n",
    "            #if neigh.satisfaction < self.model.welfare:\n",
    "            success2 = Negotiation(self.model, neigh, a).start()\n",
    "            if not success2 and neigh.motivation - gain <= 0:\n",
    "                neigh.motivation /= 2\n",
    "            else:\n",
    "                neigh.motivation += gain if success2 else -gain\n",
    "            #neigh.motivation = max(.000001, neigh.motivation)\n",
    "        \n",
    "        # TO ADD\n",
    "        for no_conflict in no_conflicts:\n",
    "            continue\n",
    "        \n",
    "        self.step += 1\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ac1da",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "0ea1fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceModel(mesa.Model):\n",
    "\n",
    "    def __invert_y_coord(self, grid):\n",
    "        return grid[::-1]\n",
    "\n",
    "    def __init__(self, params, seed=None):\n",
    "        \"\"\"\n",
    "            Create a continuous space model with discretized time with the given map (2D array).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Retrieve params\n",
    "        self.params = params\n",
    "        card = params[\"map\"]\n",
    "\n",
    "        # Set seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        # Params\n",
    "        self.EXTRA_BORDER = 0\n",
    "        self.card = self.__invert_y_coord(card)\n",
    "        self.grid = mesa.space.ContinuousSpace(x_max = len(self.card[0]) + self.EXTRA_BORDER, y_max = len(self.card) + self.EXTRA_BORDER, torus = True, x_min=-self.EXTRA_BORDER, y_min=-self.EXTRA_BORDER)\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "        self.obstacles = []\n",
    "        self.welfare = 0 # Initial welfare\n",
    "        self.objectives = []\n",
    "\n",
    "        # Debug\n",
    "        self.msgs = []\n",
    "        \n",
    "        self.num_agents = 0\n",
    "        objective_id = 0\n",
    "        # Create agents\n",
    "        for y in range(len(self.card)):\n",
    "            for x in range(len(self.card[y])):\n",
    "                obj = self.card[y][x]\n",
    "                if obj == 1: # Agent\n",
    "                    a = Ped(self, (x, y))\n",
    "                    a.unique_id = self.num_agents\n",
    "                    self.num_agents += 1\n",
    "                    self.schedule.add(a)\n",
    "                    self.grid.place_agent(a, a.position)\n",
    "                elif obj == 2: # Obstacle\n",
    "                    o = Obstacle(self, (x, y))\n",
    "                    self.grid.place_agent(o, o.position)\n",
    "                    self.obstacles.append(o.position)\n",
    "                elif obj == 3: # Multiple objectives possible\n",
    "                    o = Objective(self, (x, y), objective_id)\n",
    "                    objective_id += 1\n",
    "                    self.objectives.append(o)\n",
    "                    self.grid.place_agent(o, o.position)\n",
    "                # Otherwise empty\n",
    "        \n",
    "        # Update map for pathfinding\n",
    "        self.card = transform_grid(self.card)\n",
    "        \n",
    "        # Add objective for all agents\n",
    "        # For simplification purposes, let us assume agents take the farthest objective.\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, Ped):\n",
    "                dist = lambda o: np.linalg.norm(np.array(agent.position) - np.array(o.position))\n",
    "                agent.set_objective(max(self.objectives, key=dist))\n",
    "        \n",
    "        # Init agents\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, Ped):\n",
    "                agent.init()\n",
    "    \n",
    "    def log(self, msg):\n",
    "        self.msgs.append(msg)\n",
    "    \n",
    "    def reset_log(self):\n",
    "        self.msgs = []\n",
    "\n",
    "    def step(self):\n",
    "        DELTA = 3 # attention at 100% here\n",
    "        # Make step all agents\n",
    "        self.schedule.step()\n",
    "        \n",
    "        match self.params[\"model\"]:\n",
    "            case \"first\":\n",
    "                for a in self.schedule.agents:\n",
    "                    if not a.active:\n",
    "                        continue\n",
    "\n",
    "                    ### Negotiation\n",
    "                    # Negotiation has to happen in all agent's loop after they *all* moved first in order to deal with updated positions. \n",
    "                    \n",
    "                    # self.position is discrete for now, however, we should consider comparing distances in float later\n",
    "                    for neigh in self.grid.get_neighbors(a.position, DELTA, False):\n",
    "                        if isinstance(neigh, Ped) and neigh.active and not neigh.alert:\n",
    "                            if neigh.unique_id != a.unique_id:\n",
    "                                a.negotiate(neigh)\n",
    "                                break\n",
    "            case \"second\":\n",
    "                # Doublons dans négotiations, regroupement des sous-groupes, la sélection des groupes de négotiation n'est pas triviale.\n",
    "                for a in self.schedule.agents:\n",
    "                    if not a.active or a.negotiating:\n",
    "                        continue\n",
    "                    neighbors = list(filter(lambda neigh: isinstance(neigh, Ped) and neigh.active and not neigh.negotiating, self.grid.get_neighbors(a.position, DELTA, False)))\n",
    "                    neighbors.insert(0, a)\n",
    "                    if len(neighbors) > 1:\n",
    "                        #print(list(map(lambda a: f\"{a.unique_id} agent\", neighbors)))\n",
    "                        vote = Vote(self, neighbors)\n",
    "                        vote.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea14a6",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0257b",
   "metadata": {},
   "source": [
    "## Old visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "8cbbe774-d6c4-4c85-98c8-fdc8b7d03de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee2d2371b98435d964d39c90119b37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mesa.visualization import SolaraViz, make_plot_measure, make_space_matplotlib\n",
    "from mesa.experimental import JupyterViz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('hsv')\n",
    "\n",
    "def agent_portrayal(agent):\n",
    "    if isinstance(agent, Ped):\n",
    "        color = cmap(agent.unique_id*10)\n",
    "        if agent.alert:\n",
    "            color = cmap(agent.unique_id*10 - 10)\n",
    "        return {\n",
    "            \"color\": color,\n",
    "            \"size\": 50,\n",
    "        }\n",
    "    elif isinstance(agent, Obstacle):\n",
    "        return {\n",
    "            \"color\": \"tab:red\",\n",
    "            \"shape\": \"s\",\n",
    "            \"size\":100,\n",
    "        }\n",
    "    elif isinstance(agent, Objective):\n",
    "        return {\n",
    "            \"color\": \"tab:green\",\n",
    "            \"shape\": \"x\",\n",
    "            \"size\":80,\n",
    "        }\n",
    "\n",
    "model_params = {\n",
    "    \"map\": map2,\n",
    "    \"negotiation\": \"wait_only\"\n",
    "}\n",
    "\n",
    "# Create initial model instance\n",
    "model1 = SpaceModel(model_params)\n",
    "\n",
    "SpaceGraph = make_space_matplotlib(agent_portrayal)\n",
    "\n",
    "page = SolaraViz(\n",
    "    model1,\n",
    "    components=[SpaceGraph],\n",
    "    model_params=model_params,\n",
    "    name=\"Space Model\",\n",
    ")\n",
    "# This is required to render the visualization in the Jupyter notebook\n",
    "page\n",
    "\n",
    "# injecter des exemples\n",
    "# approfondir choix social et voir après les propriétés et thms du choix social, évaluer le modèle sur des exemples spéciqiues concrets qui marchent\n",
    "# écrire concis et ajouter formalisme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea784e-dc52-4856-9dca-c9f340fd4b78",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "584ff704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c25c991fb44c1787d8d1ac6f9bb1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.figure import Figure\n",
    "import matplotlib as mpl\n",
    "import solara\n",
    "\n",
    "# Components\n",
    "\n",
    "@solara.component\n",
    "def MarkdownWithColor(txts, color):\n",
    "    for txt in txts:\n",
    "        solara.Markdown(txt, style={\"color\": color})\n",
    "\n",
    "def normalize_to_8bit(rgb_normalized):\n",
    "    # Multiply each component by 255 and round to the nearest integer\n",
    "    return tuple(int(component * 255) for component in rgb_normalized)\n",
    "\n",
    "import webcolors\n",
    "\n",
    "# Function to find the closest color name\n",
    "def closest_color(requested_color):\n",
    "    min_colors = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - requested_color[0]) ** 2\n",
    "        gd = (g_c - requested_color[1]) ** 2\n",
    "        bd = (b_c - requested_color[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "def get_contrasted_color(rgb):\n",
    "    # Calculate brightness using the luminosity method\n",
    "    brightness = 0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]\n",
    "    \n",
    "    # Return black for light colors, white for dark colors\n",
    "    if brightness > 128:\n",
    "        return (0, 0, 0)  # Black\n",
    "    else:\n",
    "        return (255, 255, 255)  # White\n",
    "\n",
    "def get_complementary_color(rgb):\n",
    "    # Calculate the complementary color\n",
    "    return tuple(255 - component for component in rgb)\n",
    "\n",
    "# Main visualization\n",
    "\n",
    "step = solara.reactive(0)\n",
    "seed = solara.reactive(np.random.randint(0, 2<<32-1))\n",
    "debug = solara.reactive(True)\n",
    "jump = solara.reactive(0)\n",
    "log = solara.reactive(True)\n",
    "stats = solara.reactive(True)\n",
    "\n",
    "@solara.component\n",
    "def SpaceVisualization(clazz, params):\n",
    "    \n",
    "    ### Utility\n",
    "    def format_path(path):\n",
    "        if path is None:\n",
    "            return \"[]\"\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        return list(map(cell, path))\n",
    "    \n",
    "    ### Model\n",
    "    model, set_model = solara.use_state(clazz(params, seed=int(seed.value)))\n",
    "\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.subplots()\n",
    "    #ax.grid(which='major', color='black', linestyle='--', linewidth=.2)\n",
    "    grid = model.grid\n",
    "\n",
    "    # Plot borders (temp fix for fixed grid)\n",
    "    c = .5\n",
    "    for (x, y) in [(-c, -c), (grid.width+c, -c), (grid.width+c, grid.height+c), (-c, grid.height+c)]:\n",
    "        ax.scatter(x, y, marker='+', c='blue')\n",
    "    \n",
    "    # Plot extended borders\n",
    "    border = 0\n",
    "    for (x, y) in [(-border, -border), (grid.width+border, -border), (grid.width+border, grid.height+border), (-border, grid.height+border)]:\n",
    "        ax.scatter(x, y, marker='+', c='black', linewidths=0)\n",
    "\n",
    "    # Plot agents\n",
    "    cmap = mpl.colormaps['plasma']\n",
    "\n",
    "    if len(model.objectives) > 1:\n",
    "        colors = cmap(np.linspace(0, 1, len(model.objectives)))\n",
    "    else:\n",
    "        # -- Take colors at regular intervals spanning the colormap.\n",
    "        colors = cmap(np.linspace(0, 1, len(model.schedule.agents)))\n",
    "    \n",
    "    for a in model.agents:\n",
    "        if not isinstance(a, Ped):\n",
    "            continue ## We may skip this by removing other non-agents, however they may remain useful to consider neighbor obstacles.\n",
    "        if not a.active:\n",
    "            continue\n",
    "        \n",
    "        col = None\n",
    "        if len(model.objectives) > 1:\n",
    "            col = colors[a.objective_obj.id]\n",
    "        else:\n",
    "            col = colors[a.unique_id]\n",
    "        \n",
    "        x, y = a.position\n",
    "        if debug.value:\n",
    "            # -- Trajectory\n",
    "            if len(a.path) > 1:\n",
    "                xs, ys = zip(*a.path[:min(3, len(a.path))])\n",
    "                c = col\n",
    "                # Add continuous arrow at the end of the last segment\n",
    "                ax.annotate('', xy=(xs[-1], ys[-1]), xytext=(xs[-2], ys[-2]), arrowprops=dict(edgecolor=c, facecolor=c, linewidth=1.2, width=1.2, headwidth=7, headlength=4.5, alpha=.25, zorder=0), zorder=0)\n",
    "                #ax.quiver(xs[-2], ys[-2], xs[-1] - xs[-2], ys[-1] - ys[-2], angles='xy', scale_units='xy', scale=1, color='b', linewidth=2)\n",
    "                # Plot segment just after\n",
    "                ax.plot(xs, ys, linestyle=':', color=c, linewidth=2.8, zorder=1, alpha=1)\n",
    "\n",
    "            # -- Speed\n",
    "            ax.arrow(x, y, a.direction[0] * a.speed, a.direction[1] * a.speed, width = 0.03, color='green', alpha=.5, zorder=1)\n",
    "        # -- Agent\n",
    "        ax.scatter(x, y, linewidths=12, alpha=1, color=col, zorder=2)\n",
    "        #if debug.value:\n",
    "            # -- Virtual obstacle\n",
    "            #if a.negotiating and a.colliding_point is not None:\n",
    "                #xs, ys = a.colliding_point \n",
    "                #ax.scatter(xs, ys, linewidths=18, alpha=.5, c='purple')\n",
    "        # -- Id\n",
    "        ax.annotate(a.unique_id, (x+.1, y+.1), c='black', zorder=2)\n",
    "    \n",
    "    # Plot obstacles\n",
    "    for (x, y) in model.obstacles:\n",
    "        #ax.fill([x-.5, x-.5, x+.5, x+.5], [y-.5, y+.5, y+.5, y-.5], c='red')\n",
    "        ax.scatter(x, y, c='red', linewidths=8, marker='s')\n",
    "        \n",
    "    # Plot objective (to change)\n",
    "    for obj in model.objectives:\n",
    "        x, y = obj.position\n",
    "        ax.scatter(x, y, c='green', marker='x', linewidths=10)\n",
    "    \n",
    "    # Plot grid\n",
    "    # Manually set major and minor ticks to ensure spacing is correct\n",
    "    ax.set_xticks(np.arange(-border-2, grid.width+border+2, 1), minor=False)\n",
    "    ax.set_yticks(np.arange(-border-2, grid.height+border+2, 1), minor=False)\n",
    "    ax.set_xticks(np.arange(-border-2, grid.width+border+2, .5), minor=True)\n",
    "    ax.set_yticks(np.arange(-border-2, grid.height+border+2, .5), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"gray\", linestyle='-', linewidth=.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ### Model UI\n",
    "    def model_update():\n",
    "        if jump.value == 0:\n",
    "            model.step()\n",
    "            step.value += 1\n",
    "        else:\n",
    "            for i in range(int(jump.value)):\n",
    "                if i == int(jump.value) - 1:\n",
    "                    model.reset_log()\n",
    "                model.step()\n",
    "            step.value += int(jump.value)\n",
    "            jump.value = 0\n",
    "        # Plot agents\n",
    "        for a in model.agents:\n",
    "            ax.scatter(a.position[0], a.position[1], linewidths=10)\n",
    "\n",
    "    def reset_model():\n",
    "        step.value = 0\n",
    "        set_model(clazz(params, seed=int(seed.value)))\n",
    "\n",
    "    def set_random_seed():\n",
    "        rng = np.random.default_rng()\n",
    "        seed.set(rng.integers(0, 2<<32-1))\n",
    "        reset_model()\n",
    "\n",
    "    def set_map(map):\n",
    "        params[\"map\"] = maps[int(map.split(\" \")[-1])-1]\n",
    "        reset_model()\n",
    "    \n",
    "    def set_debug():\n",
    "        debug.value = not debug.value\n",
    "    \n",
    "    def set_log():\n",
    "        log.value = not log.value\n",
    "    \n",
    "    def set_stats():\n",
    "        stats.value = not stats.value\n",
    "    \n",
    "    with solara.VBox() as main:\n",
    "        with solara.Columns():\n",
    "            solara.FigureMatplotlib(fig, dependencies=[ax, model.agents])\n",
    "                \n",
    "            # UI\n",
    "            with solara.VBox():\n",
    "                solara.Button(label=f\"Step {step}\", on_click=model_update)\n",
    "                solara.InputText(\"Jump\", value=jump)\n",
    "                solara.Button(label=f\"Reset (seed: {seed.value})\", on_click=reset_model)\n",
    "                with solara.Row(gap=\"0px\", justify=\"space-evenly\"):\n",
    "                    solara.Button(label=f\"Debug ({debug.value})\", on_click=set_debug)\n",
    "                    solara.Button(label=f\"Log ({log.value})\", on_click=set_log)\n",
    "                    solara.Button(label=f\"Agents' stats ({stats.value})\", on_click=set_stats)\n",
    "                with solara.Row():\n",
    "                    solara.Button(\"Random\", on_click=set_random_seed)\n",
    "                    solara.InputText(\"Set Seed\", value=seed)\n",
    "                with solara.Columns():\n",
    "                    solara.Select(label=\"Map\",\n",
    "                                  values=list(map(lambda x: f\"Map {x}\", list(range(1, len(maps)+1)))),\n",
    "                                  value=\"Map 2\",\n",
    "                                  on_value=set_map)\n",
    "                solara.Text(f\"Global welfare: {model.welfare}\")\n",
    "                solara.Text(f\"Negotiating mode (first model only): {params['negotiation']}\")\n",
    "                solara.Text(f\"Model: {params['model']}\")\n",
    "                if log.value:\n",
    "                    MarkdownWithColor([\"## Log\"], \"cyan\")\n",
    "                    solara.Card(\n",
    "                                children=[MarkdownWithColor([\"<br>\".join(model.msgs)], \"cyan\")],\n",
    "                                style={\"maxHeight\": \"400px\", \"overflow\": \"auto\", \"border\": \"2px solid black\", \"padding\": \"0px\"}    \n",
    "                            )\n",
    "                    # MarkdownWithColor([\"-------------- [LOG] --------------\", \"<br>\".join(model.msgs)], \"cyan\")\n",
    "        if stats.value:\n",
    "            with solara.Columns():\n",
    "                # Main\n",
    "                for a in model.agents:\n",
    "                    if not isinstance(a, Ped):\n",
    "                        continue\n",
    "                    col = None\n",
    "                    if len(model.objectives) > 1:\n",
    "                        col = colors[a.objective_obj.id]\n",
    "                    else:\n",
    "                        col = colors[a.unique_id]\n",
    "                    col = normalize_to_8bit(tuple(col[:3]))\n",
    "                    title = f\"\"\"<h1 style=\"text-shadow: 1px 1px 1px black;color: {closest_color(col)};\">Agent {a.unique_id}:</h1>\"\"\"\n",
    "                    txt = f\"\"\"<h3 style=\"line-height:1.5;background-color: rgba(0, 100, 120, 0.5); filter: blur(0.25px); color:white\">\n",
    "                    <ul>\n",
    "                    <li> Real position: {a.position} | Cell position: {convert_coords(a.position)} </li>\n",
    "                    <li> Direction: {a.direction} </li>\n",
    "                    <li> Speed: {round(a.speed, 3)} </li>\n",
    "                    <li> Objective: {a.objective} </li>\n",
    "                    <li> Path: {a.path} </li>\n",
    "                    <li> Negotiating: {a.negotiating} </li>\n",
    "                    <li> Alert: {a.alert} </li>\n",
    "                    <li> Envisioned cost: {a.current_cost} </li>\n",
    "                    <li> Motivation: {round(a.motivation, 3)} </li>\n",
    "                    <li> Satisfaction: {round(a.satisfaction, 3)} </li>\n",
    "                    <li> Influenced : {a.influenced} </li>\n",
    "                    <li> Wait : {a.wait} </li>\n",
    "                    </h3>\n",
    "                    \"\"\"\n",
    "                    MarkdownWithColor([title, txt], \"black\")\n",
    "            \n",
    "        model.reset_log()\n",
    "\n",
    "    return main\n",
    "\n",
    "params = {\n",
    "    \"map\": map2,\n",
    "    \"negotiation\": \"alt_or_wait\", # wait_only\n",
    "    \"model\": \"second\"\n",
    "}\n",
    "\n",
    "## Seeds\n",
    "# blocking: 695489792\n",
    "# 3436061971\n",
    "# 5 lost: 597585348 -> the cost should take into account the direction change\n",
    "# 1767546085: 6 lost it\n",
    "# 2686383803: 5 is dumb\n",
    "# Map 2: 3138802159 1 lost it\n",
    "# Cf. blocking cases https://www.youtube.com/watch?v=c3ITUMLz6KI\n",
    "# Map 6: interblocking 3068477672, 4232108719\n",
    "# 2556336118, 1905464572 : cool\n",
    "# 257805472 check map 3\n",
    "# 2402532377 : map 5 blocking\n",
    "\"\"\"\n",
    "Les négotiations de façon plus locales dé-fluidifient l'ensemble, à l'instar de la physique.\n",
    "L'ajout de la possibilité d'attente et de l'attente forcée des négotiations impliquent une dynamique\n",
    "de simulation naturelle entre agents comme files d'attente ou attente globale afin de laisser les décisions\n",
    "à ceux qui sont le plus libre.\n",
    "\n",
    "Point clé sur les négotiations :\n",
    "il n'y a pas de priorité dans l'ordre des négotiations entamées pour une meilleure gestion des collisions *IMMINENTES*\n",
    "effet file-indienne (par Emma) donné, i.e., interblocage. Effet de coûts statu-quo par multiples négotiations et persévérance dans les négotiations entre agents\n",
    "\n",
    "- scheduler nesté dépendant des vitesses TO DO\n",
    "- wait seulement dans imminent collision OK\n",
    "- voir la résolution de conflits par négotiation de sous-trajectoires ou trajectoires globales TO DO\n",
    "- affiner les multiples négotiations par le facteur attention et priorité de collisions/difficultés (à quantifier par mot et att cf. rapport)  TO DO\n",
    "\"\"\"\n",
    "# - Validation d'un certain nombre de propositions à travers certains scénarios, examples et démonstrations.\n",
    "# e.g. c'est celui avec le moins de contrainte qui doit/peut débloquer la situation\n",
    "# ^ section expérimentale où on commente les paramètres, notamment avec la fonction de coût, étudier les relations TO DO\n",
    "# e.g. l'importance dans l'algo de la motivation et son évolution avec le lien au nombre de steps (comparaison FS)\n",
    "# e.g. importance de fonction de coût et modélisation à différents niveaux (attente notamment) ainsi qu'évolution par màj\n",
    "# e.g. exemples propagation motivations par blocage et fonction de coût\n",
    "# e.g. votes locaux (propagation ici)\n",
    "# e.g. priorité et inertie ?\n",
    "# - montrer exécution schedulers avec algo pour voir la dynamique et biais TO DO\n",
    "# > sequential move\n",
    "# - interprétation motivation (à expliquer) comme jeu coopératif avec volonté altruiste TO DO\n",
    "# - CBS MAPF\n",
    "# - site web Olivier Thèse\n",
    "# - parler propagation questions ouvertes TO DO\n",
    "# - préparer présentation 15-20 minutes, modèle +move, algo ILLUSTRés, hypothèses choix, démonstrations (expés insistance). aprèm\n",
    "# FS 8 directions ici, sous-section comparaisons TO DO\n",
    "# fix pseudo-random\n",
    "# specify algo of dynamism\n",
    "# map 3 : 692016961\n",
    "SpaceVisualization(SpaceModel, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65872d",
   "metadata": {},
   "source": [
    "# Social Force model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960de16",
   "metadata": {},
   "source": [
    "## Agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "0ff1644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SFPed(mesa.Agent):\n",
    "    def __init__(self, model, pos):\n",
    "        super().__init__(model)\n",
    "\n",
    "        # Params\n",
    "        self.model = model\n",
    "        self.active = True\n",
    "\n",
    "        # Attributes\n",
    "        self.position = np.array(pos, dtype=np.float64)\n",
    "        self.velocity = np.array((0, 0), dtype=np.float64)\n",
    "        self.desired_vel = np.array((1, 1), dtype=np.float64)\n",
    "        self.radius = 3\n",
    "        self.mass = 10\n",
    "        self.speed = .1\n",
    "        self.direction = np.array((0, 0))\n",
    "        self.last_dir = np.array((0, 0))\n",
    "        # others?\n",
    "    \n",
    "    def init(self):\n",
    "        self.desired_vel = self.compute_desired_velocity()\n",
    "        self.velocity = self.get_next_velocity()\n",
    "        self.direction = self.get_direction()\n",
    "    \n",
    "    def set_objective(self, obj):\n",
    "        self.objective_obj = obj\n",
    "        self.objective = np.array(obj.position, dtype=np.float64)\n",
    "    \n",
    "    def is_walkable(grid, position, unique_id):\n",
    "        pos = position\n",
    "        for a in grid.get_neighbors(pos, .1, True):\n",
    "            if a.unique_id != unique_id and not isinstance(a, Objective):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def compute_desired_velocity(self):\n",
    "        direction_to_objective = self.objective - self.position\n",
    "        # Normalize\n",
    "        distance_to_objective = np.linalg.norm(direction_to_objective)\n",
    "        \n",
    "        if distance_to_objective > 0:\n",
    "            desired_velocity = self.speed * direction_to_objective / distance_to_objective\n",
    "        else:\n",
    "            desired_velocity = np.zeros_like(self.position)\n",
    "        \n",
    "        return desired_velocity\n",
    "    \n",
    "    # Forces\n",
    "    def compute_ped_repulsion_force(self):\n",
    "        agents = self.model.schedule.agents\n",
    "        F = np.zeros_like(self.position)\n",
    "        for agent in agents:\n",
    "            if isinstance(agent, SFPed):\n",
    "                if agent.unique_id != self.unique_id:\n",
    "                    distance = np.linalg.norm(self.position - agent.position)\n",
    "                    if distance < self.radius:\n",
    "                        repulsion_force = (self.position - agent.position) / (distance**2)\n",
    "                        F += repulsion_force\n",
    "        return F\n",
    "    \n",
    "    def compute_obs_repulsion_force(self):\n",
    "        F = np.zeros_like(self.position)\n",
    "        for obs in self.model.obstacles:\n",
    "            obstacle = np.array(obs, dtype=np.float64)\n",
    "            distance = np.linalg.norm(self.position - obstacle)\n",
    "            if distance < self.radius:\n",
    "                obstacle_force = (self.position - obstacle) / (distance**2)\n",
    "                F += obstacle_force\n",
    "        return F\n",
    "        \n",
    "    def compute_objective_force(self, tau):\n",
    "        return (1/tau) * (self.objective - self.position)\n",
    "    \n",
    "    def compute_velocity_force(self):\n",
    "        return self.mass * (self.desired_vel - self.velocity)\n",
    "\n",
    "    def compute_forces(self):\n",
    "        tau = 1\n",
    "        return self.compute_ped_repulsion_force() + self.compute_obs_repulsion_force() + self.compute_objective_force(tau) + self.compute_velocity_force()\n",
    "\n",
    "    def get_next_velocity(self):\n",
    "        # t + delta t velocity, i.e., t + 1 in discretized time\n",
    "        return self.velocity + self.compute_forces() / self.mass\n",
    "\n",
    "    def get_direction(self):\n",
    "        end = self.velocity\n",
    "        data = end\n",
    "\n",
    "        if not (data == 0).all():\n",
    "            data = data / np.linalg.norm(data)\n",
    "        \n",
    "        def round_up(x):\n",
    "            sign = 1\n",
    "            if x < 0:\n",
    "                sign = -1\n",
    "            val = abs(x)\n",
    "            if val < .05:\n",
    "                val = 0\n",
    "            elif not np.isnan(val):\n",
    "                val = math.ceil(val)\n",
    "            else:\n",
    "                return 0\n",
    "            return min(1, val) * sign\n",
    "        \n",
    "        return list(map(round_up, data)) # ceil may be too strong, a threshold can be required\n",
    "        #return end\n",
    "\n",
    "    def get_next_position(self, dir):\n",
    "        # at t + 1\n",
    "        return self.position + dir\n",
    "\n",
    "    def move(self, dir, pos):\n",
    "        self.direction = dir\n",
    "        self.position = pos\n",
    "        self.model.grid.move_agent(self, self.position)\n",
    "\n",
    "    def step(self):\n",
    "        # End\n",
    "        if not self.active:\n",
    "            return\n",
    "        \n",
    "        # Move as init takes care of first step of cognition\n",
    "        dir = self.direction\n",
    "        pos = self.get_next_position(dir)\n",
    "        if is_walkable(self.model.grid, convert_coords(pos), self.unique_id):\n",
    "            self.move(dir, pos)\n",
    "            self.last_dir = dir\n",
    "        else:\n",
    "            # Check if it is possible to slide\n",
    "            # y first\n",
    "            dir_y = dir[:]\n",
    "            dir_y[0] = 0\n",
    "            pos_y = self.get_next_position(dir_y)\n",
    "            dir_x = dir[:]\n",
    "            dir_x[1] = 0\n",
    "            pos_x = self.get_next_position(dir_x)\n",
    "            if is_walkable(self.model.grid, pos_y, self.unique_id):\n",
    "                self.move(dir_y, pos_y)\n",
    "                self.last_dir = dir_y\n",
    "            elif is_walkable(self.model.grid, pos_x, self.unique_id):\n",
    "                self.move(dir_x, pos_x)\n",
    "                self.last_dir = dir_x\n",
    "        \n",
    "        # End\n",
    "        if np.array_equal(np.array(convert_coords(self.position), dtype=np.float64), self.objective):\n",
    "            self.active = False\n",
    "            self.model.grid.remove_agent(self)\n",
    "            return\n",
    "        \n",
    "        # Think\n",
    "        self.velocity = self.get_next_velocity()\n",
    "        self.direction = self.get_direction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f214d1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "df473c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFModel(mesa.Model):\n",
    "    def __init__(self, params, seed=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Retrieve params\n",
    "        self.params = params\n",
    "        card = params[\"map\"]\n",
    "\n",
    "        # Logs\n",
    "        self.msgs = []\n",
    "\n",
    "        # Set seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Map and scheduler\n",
    "        self.EXTRA_BORDER = 0\n",
    "        self.grid = mesa.space.ContinuousSpace(x_max = len(card[0]) + self.EXTRA_BORDER, y_max = len(card) + self.EXTRA_BORDER, torus = True, x_min=-self.EXTRA_BORDER, y_min=-self.EXTRA_BORDER)\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "        self.obstacles = []\n",
    "        self.objectives = []\n",
    "\n",
    "        # Others\n",
    "        self.num_agents = 0\n",
    "        objective_id = 0\n",
    "\n",
    "        # Create agents\n",
    "        for y in range(len(card)):\n",
    "            for x in range(len(card[y])):\n",
    "                obj = card[y][x]\n",
    "                if obj == 1: # Agent\n",
    "                    a = SFPed(self, (x, y))\n",
    "                    a.unique_id = self.num_agents\n",
    "                    self.num_agents += 1\n",
    "                    self.schedule.add(a)\n",
    "                    self.grid.place_agent(a, a.position)\n",
    "                elif obj == 2: # Obstacle\n",
    "                    o1 = Obstacle(self, (x, y))\n",
    "                    self.grid.place_agent(o1, o1.position)\n",
    "                    self.obstacles.append(o1.position)\n",
    "                elif obj == 3: # Multiple objectives possible\n",
    "                    o = Objective(self, (x, y), objective_id)\n",
    "                    objective_id += 1\n",
    "                    self.objectives.append(o)\n",
    "                    self.grid.place_agent(o, o.position)\n",
    "                # Otherwise empty\n",
    "        \n",
    "        # Add objective for all agents\n",
    "        # For simplification purposes, let us assume agents take the farthest objective.\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, SFPed):\n",
    "                dist = lambda o: np.linalg.norm(np.array(agent.position) - np.array(o.position))\n",
    "                agent.set_objective(max(self.objectives, key=dist))\n",
    "        \n",
    "        # Init agents\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, SFPed):\n",
    "                agent.init()\n",
    "    \n",
    "    def reset_log(self):\n",
    "        self.msgs = []\n",
    "    \n",
    "    def step(self):\n",
    "        self.schedule.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "8902a64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SFModel at 0x34379a800>"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_params = {\"map\": map2}\n",
    "SFModel(sf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a092f80",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "b2c759c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348a42d3f6bf49b789566fed794915fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.figure import Figure\n",
    "import matplotlib as mpl\n",
    "import solara\n",
    "import time\n",
    "\n",
    "# Components\n",
    "\n",
    "@solara.component\n",
    "def MarkdownWithColor(txts, color):\n",
    "    for txt in txts:\n",
    "        solara.Markdown(txt, style={\"color\": color})\n",
    "\n",
    "def normalize_to_8bit(rgb_normalized):\n",
    "    # Multiply each component by 255 and round to the nearest integer\n",
    "    return tuple(int(component * 255) for component in rgb_normalized)\n",
    "\n",
    "import webcolors\n",
    "\n",
    "# Function to find the closest color name\n",
    "def closest_color(requested_color):\n",
    "    min_colors = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - requested_color[0]) ** 2\n",
    "        gd = (g_c - requested_color[1]) ** 2\n",
    "        bd = (b_c - requested_color[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "def get_contrasted_color(rgb):\n",
    "    # Calculate brightness using the luminosity method\n",
    "    brightness = 0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]\n",
    "    \n",
    "    # Return black for light colors, white for dark colors\n",
    "    if brightness > 128:\n",
    "        return (0, 0, 0)  # Black\n",
    "    else:\n",
    "        return (255, 255, 255)  # White\n",
    "\n",
    "def get_complementary_color(rgb):\n",
    "    # Calculate the complementary color\n",
    "    return tuple(255 - component for component in rgb)\n",
    "\n",
    "# Main visualization\n",
    "\n",
    "step = solara.reactive(0)\n",
    "seed = solara.reactive(np.random.randint(0, 2<<32-1))\n",
    "debug = solara.reactive(True)\n",
    "jump = solara.reactive(0)\n",
    "log = solara.reactive(True)\n",
    "stats = solara.reactive(True)\n",
    "run = solara.reactive(False)\n",
    "result = None\n",
    "\n",
    "@solara.component\n",
    "def SpaceVisualization(clazz, params):\n",
    "    \n",
    "    ### Utility\n",
    "    def format_path(path):\n",
    "        if path is None:\n",
    "            return \"[]\"\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        return list(map(cell, path))\n",
    "    \n",
    "    ### Model\n",
    "    model, set_model = solara.use_state(clazz(params, seed=int(seed.value)))\n",
    "\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.subplots()\n",
    "    #ax.grid(which='major', color='black', linestyle='--', linewidth=.2)\n",
    "    grid = model.grid\n",
    "\n",
    "    # Plot borders (temp fix for fixed grid)\n",
    "    c = .5\n",
    "    for (x, y) in [(-c, -c), (grid.width+c, -c), (grid.width+c, grid.height+c), (-c, grid.height+c)]:\n",
    "        ax.scatter(x, y, marker='+', c='blue')\n",
    "    \n",
    "    # Plot extended borders\n",
    "    border = 0\n",
    "    for (x, y) in [(-border, -border), (grid.width+border, -border), (grid.width+border, grid.height+border), (-border, grid.height+border)]:\n",
    "        ax.scatter(x, y, marker='+', c='black', linewidths=0)\n",
    "\n",
    "    # Plot agents\n",
    "    cmap = mpl.colormaps['plasma']\n",
    "\n",
    "    if len(model.objectives) > 1:\n",
    "        colors = cmap(np.linspace(0, 1, len(model.objectives)))\n",
    "    else:\n",
    "        # -- Take colors at regular intervals spanning the colormap.\n",
    "        colors = cmap(np.linspace(0, 1, len(model.schedule.agents)))\n",
    "    \n",
    "    for a in model.agents:\n",
    "        if not isinstance(a, SFPed):\n",
    "            continue ## We may skip this by removing other non-agents, however they may remain useful to consider neighbor obstacles.\n",
    "        if not a.active:\n",
    "            continue\n",
    "        \n",
    "        col = None\n",
    "        if len(model.objectives) > 1:\n",
    "            col = colors[a.objective_obj.id]\n",
    "        else:\n",
    "            col = colors[a.unique_id]\n",
    "        \n",
    "        x, y = a.position\n",
    "        if debug.value:\n",
    "            # -- Trajectory\n",
    "            xs, ys = (a.position[0], a.position[0] + a.direction[0]), (a.position[1], a.position[1] + a.direction[1])\n",
    "            c = col\n",
    "            # Add continuous arrow at the end of the last segment\n",
    "            #ax.annotate('', xy=(xs[-1], ys[-1]), xytext=(xs[-2], ys[-2]), arrowprops=dict(edgecolor=c, facecolor=c, linewidth=1.2, width=1.2, headwidth=7, headlength=4.5, alpha=.25, zorder=0), zorder=0)\n",
    "            ax.quiver(xs[-2], ys[-2], xs[-1] - xs[-2], ys[-1] - ys[-2], angles='xy', scale_units='xy', scale=1, color=c, linewidth=.1)\n",
    "            # Plot segment just after\n",
    "            #ax.plot(xs, ys, linestyle=':', color=c, linewidth=2.8, zorder=1, alpha=1)\n",
    "\n",
    "            # -- Speed\n",
    "            #ax.arrow(x, y, a.direction[0] * a.speed, a.direction[1] * a.speed, width = 0.03, color='green', alpha=.5, zorder=1)\n",
    "        # -- Agent\n",
    "        ax.scatter(x, y, linewidths=12, alpha=1, color=col, zorder=2)\n",
    "        # -- Id\n",
    "        ax.annotate(a.unique_id, (x+.1, y+.1), c='black', zorder=2)\n",
    "    \n",
    "    # Plot obstacles\n",
    "    for (x, y) in model.obstacles:\n",
    "        #ax.fill([x-.5, x-.5, x+.5, x+.5], [y-.5, y+.5, y+.5, y-.5], c='red')\n",
    "        ax.scatter(x, y, c='red', linewidths=8, marker='s')\n",
    "        \n",
    "    # Plot objective (to change)\n",
    "    for obj in model.objectives:\n",
    "        x, y = obj.position\n",
    "        ax.scatter(x, y, c='green', marker='x', linewidths=10)\n",
    "    \n",
    "    # Plot grid\n",
    "    # Manually set major and minor ticks to ensure spacing is correct\n",
    "    ax.set_xticks(np.arange(-border-2, grid.width+border+2, 1), minor=False)\n",
    "    ax.set_yticks(np.arange(-border-2, grid.height+border+2, 1), minor=False)\n",
    "    ax.set_xticks(np.arange(-border-2, grid.width+border+2, .5), minor=True)\n",
    "    ax.set_yticks(np.arange(-border-2, grid.height+border+2, .5), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"gray\", linestyle='-', linewidth=.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ### Model UI\n",
    "    def model_update():\n",
    "        if jump.value == 0:\n",
    "            model.step()\n",
    "            step.value += 1\n",
    "        else:\n",
    "            for i in range(int(jump.value)):\n",
    "                if i == int(jump.value) - 1:\n",
    "                    model.reset_log()\n",
    "                model.step()\n",
    "            step.value += int(jump.value)\n",
    "            jump.value = 0\n",
    "        # Plot agents\n",
    "        for a in model.agents:\n",
    "            ax.scatter(a.position[0], a.position[1], linewidths=10)\n",
    "\n",
    "    def reset_model():\n",
    "        step.value = 0\n",
    "        set_model(clazz(params, seed=int(seed.value)))\n",
    "\n",
    "    def set_random_seed():\n",
    "        rng = np.random.default_rng()\n",
    "        seed.set(rng.integers(0, 2<<32-1))\n",
    "        reset_model()\n",
    "\n",
    "    def set_map(map):\n",
    "        params[\"map\"] = maps[int(map.split(\" \")[-1])-1]\n",
    "        reset_model()\n",
    "    \n",
    "    def set_debug():\n",
    "        debug.value = not debug.value\n",
    "    \n",
    "    def set_log():\n",
    "        log.value = not log.value\n",
    "    \n",
    "    def set_stats():\n",
    "        stats.value = not stats.value\n",
    "\n",
    "    def set_run():\n",
    "        import threading\n",
    "        run.value = not run.value\n",
    "        if run.value:\n",
    "            threading.Thread(target=run_simulation, args=(True, model.agents.set)).start()\n",
    "            #result: solara.Result[bool] = solara.use_thread(run_simulation, dependencies=[])  # noqa: SH102\n",
    "            #for i in range(50):\n",
    "            #    model.step()\n",
    "            #    time.sleep(.1)\n",
    "        elif result is not None:\n",
    "            #result.cancel()\n",
    "            pass\n",
    "    \n",
    "    def run_simulation(f, set_agents):\n",
    "        for i in range(50):\n",
    "            model.step()\n",
    "            set_agents(model.agents)\n",
    "            time.sleep(.1)\n",
    "\n",
    "    with solara.VBox() as main:\n",
    "        with solara.Columns():\n",
    "            solara.FigureMatplotlib(fig, dependencies=[ax, model.agents])\n",
    "                \n",
    "            # UI\n",
    "            with solara.VBox():\n",
    "                solara.Button(label=f\"Step {step}\", on_click=model_update)\n",
    "                solara.InputText(\"Jump\", value=jump)\n",
    "                solara.Button(label=f\"Reset (seed: {seed.value})\", on_click=reset_model)\n",
    "                with solara.Row(gap=\"0px\", justify=\"space-evenly\"):\n",
    "                    solara.Button(label=\"Run\" if not run.value else \"Stop\", on_click=set_run)\n",
    "                    solara.Button(label=f\"Debug ({debug.value})\", on_click=set_debug)\n",
    "                    solara.Button(label=f\"Log ({log.value})\", on_click=set_log)\n",
    "                    solara.Button(label=f\"Agents' stats ({stats.value})\", on_click=set_stats)\n",
    "                with solara.Row():\n",
    "                    solara.Button(\"Random\", on_click=set_random_seed)\n",
    "                    solara.InputText(\"Set Seed\", value=seed)\n",
    "                with solara.Columns():\n",
    "                    solara.Select(label=\"Map\",\n",
    "                                  values=list(map(lambda x: f\"Map {x}\", list(range(1, len(maps)+1)))),\n",
    "                                  value=\"Map 2\",\n",
    "                                  on_value=set_map)\n",
    "                #solara.Text(f\"Global welfare: {model.welfare}\")\n",
    "                #solara.Text(f\"Negotiating mode (first model only): {params['negotiation']}\")\n",
    "                #solara.Text(f\"Model: {params['model']}\")\n",
    "                if log.value:\n",
    "                    MarkdownWithColor([\"## Log\"], \"cyan\")\n",
    "                    solara.Card(\n",
    "                                children=[MarkdownWithColor([\"<br>\".join(model.msgs)], \"cyan\")],\n",
    "                                style={\"maxHeight\": \"400px\", \"overflow\": \"auto\", \"border\": \"2px solid black\", \"padding\": \"0px\"}    \n",
    "                            )\n",
    "                    # MarkdownWithColor([\"-------------- [LOG] --------------\", \"<br>\".join(model.msgs)], \"cyan\")\n",
    "        if stats.value:\n",
    "            with solara.Columns():\n",
    "                # Main\n",
    "                for a in model.agents:\n",
    "                    if not isinstance(a, SFPed):\n",
    "                        continue\n",
    "                    col = None\n",
    "                    if len(model.objectives) > 1:\n",
    "                        col = colors[a.objective_obj.id]\n",
    "                    else:\n",
    "                        col = colors[a.unique_id]\n",
    "                    col = normalize_to_8bit(tuple(col[:3]))\n",
    "                    title = f\"\"\"<h1 style=\"text-shadow: 1px 1px 1px black;color: {closest_color(col)};\">Agent {a.unique_id}:</h1>\"\"\"\n",
    "                    txt = f\"\"\"<h3 style=\"line-height:1.5;background-color: rgba(0, 100, 120, 0.5); filter: blur(0.25px); color:white\">\n",
    "                    <ul>\n",
    "                    <li> Real position: {a.position} | Cell position: {convert_coords(a.position)} </li>\n",
    "                    <li> Direction: {a.direction} </li>\n",
    "                    <li> Previous dir: {a.direction} </li>\n",
    "                    <li> Velocity: {a.velocity} </li>\n",
    "                    <li> Objective: {a.objective} </li>\n",
    "                    </h3>\n",
    "                    \"\"\"\n",
    "                    MarkdownWithColor([title, txt], \"black\")\n",
    "            \n",
    "        model.reset_log()\n",
    "\n",
    "    return main\n",
    "\n",
    "sf_params = {\n",
    "    \"map\": map3,\n",
    "}\n",
    "\n",
    "SpaceVisualization(SFModel, sf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6c166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orproject1",
   "language": "python",
   "name": "orproject1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
