{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2deaf054",
   "metadata": {},
   "source": [
    "# This file has the sole purpose of conducting tests for the negotiation model between pedestrians.\n",
    "\n",
    "### A first objective is to test and develop a negotiation model based on social choice theory, regardless of the motion part\n",
    "\n",
    "The conducted tests will mainly use Mesa, a Python library developed to work with agent-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50df72-1a9b-4d5d-9686-a6044bfffd4f",
   "metadata": {},
   "source": [
    "# Social model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661f579-3095-44c9-98c4-4819499f5a9d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee672a-f3a8-41ce-84e9-4faff2ee1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f5f35b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa # version 3.0.0a4\n",
    "# mesa, pathfinding, cbs-mapf\n",
    "# Has multi-dimensional arrays and matrices. Has a large collection of\n",
    "# mathematical functions to operate on these arrays.\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "# Path finding\n",
    "# @ https://www.youtube.com/watch?v=8SigT_jhz4I\n",
    "from pathfinding.core.grid import Grid\n",
    "from pathfinding.finder.a_star import AStarFinder\n",
    "from pathfinding.core.diagonal_movement import DiagonalMovement\n",
    "\n",
    "# Comparison\n",
    "# CBS & STA* for MAPF\n",
    "import sys\n",
    "sys.path.append('./cbs_mapf')  # Add the directory containing your module\n",
    "from cbs_mapf.planner import Planner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86f245",
   "metadata": {},
   "source": [
    "## Maps and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edc247-019a-4f4e-a338-ebb28bcca030",
   "metadata": {},
   "outputs": [],
   "source": [
    "map0 = [[0,1,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,0,0,3],\n",
    "        [0,0,3,0]]\n",
    "\n",
    "map1 = [[0,0,2,2,0],\n",
    "        [1,0,0,0,1],\n",
    "        [0,0,0,0,31],\n",
    "        [2,2,2,2,0],\n",
    "        [0,0,32,0,0]]\n",
    "\n",
    "map2 = [[0,0,0,2,0,0,1],\n",
    "        [0,0,0,0,2,2,0],\n",
    "        [0,0,2,0,0,0,0],\n",
    "        [0,32,0,0,0,0,31],\n",
    "        [0,0,2,0,2,2,0],\n",
    "        [0,0,2,0,2,0,0],\n",
    "        [33,0,2,2,0,0,1]    \n",
    "       ]\n",
    "\n",
    "map3 =  [[0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 2, 2, 0, 0, 0, 1],\n",
    "         [0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 2, 2, 0, 0, 0, 0, 0],\n",
    "         [32, 0, 0, 0, 31, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 2, 0, 0, 0, 1],\n",
    "         [0, 0, 0, 0, 0, 2, 2, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 2, 2, 0, 0, 0, 0],\n",
    "        ]\n",
    "\n",
    "map4 = [\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 34, 0, 2, 32, 0, 0, 31, 0, 1, 0, 1],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1],\n",
    " [0, 35, 0, 0, 2, 0, 33, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "map5 = [\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 32, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 0, 31, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0],\n",
    " [33, 0, 0, 0, 2, 1, 2, 1, 2, 0, 2, 0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "map6 = [\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 0],\n",
    "    [0, 1, 0, 2, 0, 0, 2, 0, 1, 0],\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [42, 1, 0, 31, 0, 0, 41, 0, 1, 32],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 2, 0, 0, 2, 0, 1, 0],\n",
    "    [0, 1, 0, 2, 0, 0, 2, 0, 1, 0],\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 0],\n",
    "    [0, 0, 0, 2, 0, 0, 2, 0, 0, 0]\n",
    "]\n",
    "\n",
    "map7 = [ [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2],\n",
    "  [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0],\n",
    "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0],\n",
    "  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "  [31, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 41],\n",
    "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
    "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0],\n",
    "  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2]\n",
    "]\n",
    "\n",
    "map8 = [\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [3, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 3],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "maps = [map0, map1, map2, map3, map4, map5, map6, map7, map8]\n",
    "\n",
    "def transform_grid(card):\n",
    "    \"\"\"\n",
    "        Short utility function to only consider free (1) and obstacles (0) in the map.\n",
    "        Used to collaborate with the pathfinding library.\n",
    "    \"\"\"\n",
    "    new_map = []\n",
    "    for row in card:\n",
    "        new_col = []\n",
    "        for col in row:\n",
    "            if col == 2: # Obstacle\n",
    "                new_col.append(0)\n",
    "            else:\n",
    "                new_col.append(1)\n",
    "        new_map.append(new_col)\n",
    "    return new_map\n",
    "\n",
    "print(transform_grid(map1))\n",
    "\n",
    "def convert_coords(pos):\n",
    "    \"\"\"\n",
    "        Convert real coordinates to integer coordinates.\n",
    "    \"\"\"\n",
    "    return (round(pos[0]), round(pos[1]))\n",
    "\n",
    "def is_walkable(grid, position, unique_id):\n",
    "    pos = position\n",
    "    for a in grid.get_neighbors(pos, .1, True):\n",
    "        if a.unique_id != unique_id and not isinstance(a, Objective):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def collides(path1, path2):\n",
    "    if len(path2) < len(path1):\n",
    "        path1, path2 = path2, path1\n",
    "    # Bias of collision: the crossing is considered more important as an imminent collision\n",
    "    #if len(path1) > 1:\n",
    "    # Bias of selection: the shortest path is considered with the colliding point, i.e., the agent with the longest path is the obstacle   \n",
    "    # We may include the other colliding point later.\n",
    "    # Common path\n",
    "    for i in range(len(path1)-1):\n",
    "        p1 = path1[i]\n",
    "        p1_n = path1[i+1]\n",
    "        p2 = path2[i]\n",
    "        # Crossing paths\n",
    "        if p1_n[0] == p2[0] and p1_n[1] == p2[1]:\n",
    "            return (p2[0], p2[1])\n",
    "        # Virtual obstacle\n",
    "        if p1[0] == p2[0] and p1[1] == p2[1]:\n",
    "            return (p1[0], p1[1])\n",
    "    # Check last cell which cannot be crossing path as it has already been checked\n",
    "    if path1[len(path1)-1][0] == path2[len(path1)-1][0] and path1[len(path1)-1][1] == path2[len(path1)-1][1]:\n",
    "        return (path1[len(path1)-1][0], path1[len(path1)-1][1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b4fe1-14b4-40d9-9b54-bd07950ab48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp = transform_grid(map1[::-1])\n",
    "for r in mapp:\n",
    "    print(r)\n",
    "grid = Grid(height=5, width=5, matrix = mapp, inverse=False, grid_id=1)\n",
    "\n",
    "grid_self_pos = (0, 1)\n",
    "\n",
    "start = grid.node(grid_self_pos[0], grid_self_pos[1])\n",
    "end = grid.node(2,4)\n",
    "\n",
    "finder = AStarFinder(diagonal_movement = DiagonalMovement.always)\n",
    "path, runs = finder.find_path(start, end, grid)\n",
    "\n",
    "print(\"Found path:\")\n",
    "for p in path:\n",
    "    print((p.x, p.y), end='; ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcc9e0-bf19-4311-b79a-d8debe354bb5",
   "metadata": {},
   "source": [
    "### A first jet on preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79e9be-2c33-478f-922f-4e35540a6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give two virtual agents their features.\n",
    "motivations = [.5, .5]\n",
    "objectives = [(5,5), (-2, -3)]\n",
    "positions = [(0, 0), (3,4)]\n",
    "trajectories = [6, 4] # paths sizes\n",
    "speed = [2.4, 1.8] # m/s\n",
    "\n",
    "# Let the first proposed cost function be defined, given K1=K2=K3=1\n",
    "def cost(agent):\n",
    "    mot = motivations[agent]\n",
    "    pos = np.array(positions[agent])\n",
    "    objective = np.array(objectives[agent])\n",
    "    dist = np.linalg.norm(pos-objective)\n",
    "    size = trajectories[agent]\n",
    "    print(f\"dist of agent {agent}: {dist}\")\n",
    "    return round((4 * size) / dist + speed[agent] + (1 / mot), 3)\n",
    "\n",
    "# Same function adapted for the model below.\n",
    "def path_cost(agent, path):\n",
    "    mot = agent.motivation\n",
    "    pos = agent.position\n",
    "    goal = agent.objective\n",
    "    speed = agent.speed\n",
    "    dist = agent.model.grid.get_distance(pos, goal)\n",
    "    size = len(path)\n",
    "    if dist <= 0:\n",
    "        return -1\n",
    "    cost = round((2 * size) / dist + speed + (1 / mot), 3)\n",
    "    if size > 1:\n",
    "        for i in range(size-1):\n",
    "            if path[i] == path[i+1]:\n",
    "                # Wait process\n",
    "                cost += 5\n",
    "    return cost\n",
    "\n",
    "def estimate_trajectory(direction):\n",
    "    \"\"\"\n",
    "        This current trajectory estimation is done through linear approximation.\n",
    "    \"\"\"\n",
    "    dx, dy = direction\n",
    "    pass\n",
    "\n",
    "for agent in range(2):\n",
    "    print(f\"cost of agent {agent}: {cost(agent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d2cee",
   "metadata": {},
   "source": [
    "### A first jet on CBS-MAPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_obstacles(mapp):\n",
    "    static_obstacles = []\n",
    "    obstacle_id = 2\n",
    "    for y in range(len(mapp)):\n",
    "        for x in range(len(mapp[y])):\n",
    "            if mapp[y][x] == obstacle_id:\n",
    "                static_obstacles.append((x, y))\n",
    "    return static_obstacles\n",
    "\n",
    "def get_agent_starts(mapp):\n",
    "    agts = []\n",
    "    agt_id = 1\n",
    "    for y in range(len(mapp)):\n",
    "        for x in range(len(mapp[y])):\n",
    "            if mapp[y][x] == agt_id:\n",
    "                agts.append((x, y))\n",
    "    return agts\n",
    "\n",
    "def find_goal(mapp):\n",
    "    goal_id = 3\n",
    "    for y in range(len(mapp)):\n",
    "        for x in range(len(mapp[y])):\n",
    "            if mapp[y][x] == goal_id:\n",
    "                return (x, y)\n",
    "\n",
    "map_ = [[0,0,0,2,0,0,1], # map2\n",
    "        [0,0,2,2,2,2,0],\n",
    "        [0,0,2,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0],\n",
    "        [0,0,2,0,2,2,0],\n",
    "        [0,0,2,0,2,0,0],\n",
    "        [3,0,2,2,0,0,1]    \n",
    "       ]\n",
    "\n",
    "# Call cbs-mapf to plan\n",
    "start = get_agent_starts(map_)\n",
    "print(\"starts\", start)\n",
    "obj = find_goal(map_)\n",
    "goal = [obj for _ in range(len(start))]\n",
    "print(\"goals\", goal)\n",
    "#assert(len(start) == len(goal))\n",
    "planner = Planner(map_)\n",
    "path = planner.plan(start, goal, debug=False)\n",
    "print(\"type\", path.shape)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336c043",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "d2d501fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def get_evaluation(agents):\n",
    "    # Metrics\n",
    "    dist = 0\n",
    "    wait = 0\n",
    "    equi_vals = []\n",
    "    equi = 0\n",
    "    # Ti+, Ti*, Tau_i\n",
    "    results = [0, 0, 0]\n",
    "    for agent in agents:\n",
    "        dirty_tip = agent.global_path\n",
    "        #print(\"dirty tip\", dirty_tip)\n",
    "        # Clear paths, i.e., remove waitings for Ti+\n",
    "        tip = [dirty_tip[0]] + [b for a, b in zip(dirty_tip, dirty_tip[1:]) if a != b]\n",
    "        # But also for SFM, remove going extra-borders agents with respect to goal\n",
    "        # First, check if there is one goal reaching cell\n",
    "        stip = len(tip)\n",
    "        if isinstance(agent, SFPed):\n",
    "            objective = agent.final_objective\n",
    "            # Check if the path is reached, with some tolerance threshold for SFM only\n",
    "            last_reached_index = next((i for i, cell in enumerate(tip) if np.linalg.norm(np.array(cell) - np.array(objective)) < 2), None)\n",
    "            if last_reached_index is not None:\n",
    "                tip = tip[:last_reached_index + 1]\n",
    "                stip = len(tip)\n",
    "                #print(\"shortened path\", tip)\n",
    "                #print(\"len\", stip)\n",
    "            else:\n",
    "                # Filter out any cell that exceeds the 1.2 times the distance between the start and goal\n",
    "                tip = list(filter(lambda cell: np.linalg.norm(np.array(cell) - np.array(objective)) < 1.2 * np.linalg.norm(np.array(tip[0]) - np.array(objective)), dirty_tip))\n",
    "                stip = -1 # still the goal was not reached\n",
    "        tis = agent.optimal_path\n",
    "        tau = agent.tau\n",
    "        # Distance metric\n",
    "        stis = len(tis)\n",
    "        #print(\"lenstis\", stis)\n",
    "        dist += (stis / stip) if stip > 0 else 0 # Infinity size(T_i^+)\n",
    "        # Wait metric\n",
    "        wait += tau - len(tip)\n",
    "        # Equity metric\n",
    "        equi_vals.append(wait)\n",
    "    # Compute metrics\n",
    "    n = len(agents)\n",
    "    results[0] = dist / n\n",
    "    results[1] = wait / n\n",
    "    results[2] = np.std(equi_vals, ddof=1) # unbiased for sample population\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddf017",
   "metadata": {},
   "source": [
    "## Agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "6f0624f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ped(mesa.Agent):\n",
    "    \n",
    "    def __init__(self, model, pos):\n",
    "        super().__init__(model)\n",
    "\n",
    "        # Evaluation\n",
    "        self.global_path = [] # Tip\n",
    "        self.optimal_path = [] # Tis\n",
    "        self.tau = 0 # Taui\n",
    "\n",
    "        # If the agent still didn't reach its objective\n",
    "        self.active = True\n",
    "\n",
    "        # Traits\n",
    "        self.motivation = min(.3, np.random.rand()) # 0.3-1\n",
    "        self.speed = np.random.rand() + 1\n",
    "        self.satisfaction = np.random.uniform(-3, 1) # Satisfaction threshold of the current situation the agent is in.\n",
    "        # The lower the satisfaction the more an agent can acclimate to the others.\n",
    "\n",
    "        self.position = pos\n",
    "        self.direction = None\n",
    "        self.alert = False\n",
    "        self.wait = False\n",
    "        self.path = None\n",
    "        self.negotiating = False\n",
    "        self.current_cost = -1\n",
    "        self.alternatives = {}\n",
    "        self.influenced = False\n",
    "    \n",
    "    def set_objective(self, obj):\n",
    "        self.objective_obj = obj\n",
    "        self.objective = obj.position\n",
    "        \n",
    "        # Evaluation, should be made only once\n",
    "        self.optimal_path = list(self.find_path())\n",
    "\n",
    "    def find_path(self, obstacles=None, diag=True):\n",
    "        #TODO add current positions as obstacles\n",
    "        grid = None\n",
    "        if obstacles is None:\n",
    "            grid = Grid(height=len(self.model.card), width=len(self.model.card[0]), matrix = self.model.card, inverse=False, grid_id=1)\n",
    "        else:\n",
    "            matrix = copy.deepcopy(self.model.card)\n",
    "            for obstacle in obstacles:\n",
    "                x, y = obstacle\n",
    "                matrix[y][x] = 0\n",
    "            grid = Grid(height=len(self.model.card), width=len(self.model.card[0]), matrix = matrix, inverse=False, grid_id=2)\n",
    "        \n",
    "        grid_self_pos = convert_coords(self.position)\n",
    "\n",
    "        start = grid.node(grid_self_pos[0], grid_self_pos[1])\n",
    "        end = grid.node(self.objective[0], self.objective[1])\n",
    "\n",
    "        finder = AStarFinder(diagonal_movement = DiagonalMovement.always if diag else DiagonalMovement.never)\n",
    "        path, runs = finder.find_path(start, end, grid)\n",
    "\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        path = list(map(cell, path))\n",
    "        return None if len(path) == 0 else tuple(path) # Convert the paths to a tuple of pairs as it is hashable.\n",
    "\n",
    "    def get_direction(self):\n",
    "        if self.path is not None and len(self.path) > 1:\n",
    "            end = np.array((self.path[1][0], self.path[1][1]))\n",
    "            start = np.array((self.position[0], self.position[1]))\n",
    "            data = end - start\n",
    "\n",
    "            if not (data == 0).all():\n",
    "                data = data / np.linalg.norm(data)\n",
    "            \n",
    "            def round_to_half_unit(n):\n",
    "                return round(n * 2) / 2\n",
    "            \n",
    "            self.direction = list(map(round, data))\n",
    "            # self.model.log(f\"{self.unique_id} changed direction.\")\n",
    "            # self.model.log(f\"{self.unique_id}'s current path: {self.path}\")\n",
    "    \n",
    "    \"\"\"\n",
    "        Self utility function to consider a proposed path with its associated cost.\n",
    "        If the current agent finds the proposition considerable, relative to its satisfaction and the proposed cost,\n",
    "        then it reconsiders the best suitable alternative (collision-free) by re-evaluating its associated cost (diminish it).\n",
    "    \"\"\"\n",
    "    def consider_alternative(self, path, cost):\n",
    "        # Sort alternatives in ascending cost order, for now the agents want to avoid collision\n",
    "        if len(self.alternatives) <= 0:\n",
    "            self.compute_set()\n",
    "            if len(self.alternatives) <= 0: # Blocked agent\n",
    "                return False\n",
    "            \n",
    "        alts = sorted(self.alternatives, key=self.alternatives.get)\n",
    "        # Get the first collision-free alternative\n",
    "        best_alt = None\n",
    "        for alt in alts:\n",
    "            if collides(alt, path) is None: # Found one\n",
    "                best_alt = alt\n",
    "                break\n",
    "        # If a CF-trajectory was not found, find a potential alternative\n",
    "        best_alt_2 = None\n",
    "        if best_alt is None:\n",
    "            # We didn't find an alternative, compute one\n",
    "            self.colliding_point = collides(alts[0], path)\n",
    "            colliding_points = [self.colliding_point]\n",
    "            for neigh in self.model.grid.get_neighbors(self.position, 2, False):\n",
    "                if isinstance(neigh, Ped) and neigh.active:\n",
    "                    colliding_points.append(neigh.position)\n",
    "            best_alt = self.find_path(obstacles = colliding_points) # Compute a new CF trajectory (part of the recompute actually)\n",
    "            best_alt_2 = self.find_path(obstacles = colliding_points, diag=False)\n",
    "\n",
    "            if best_alt is None and best_alt_2 is None: # If not found, get the best possible alternative w.r.t. the given cost\n",
    "                self.model.log(f\"{self.unique_id} didn't find a collision-free path, best alternative.\")\n",
    "                best_alts = list(filter(lambda p: self.alternatives[p] - self.motivation <= cost, alts))\n",
    "                if len(best_alts) > 0:\n",
    "                    best_alt = min(best_alts)\n",
    "            \n",
    "            # Save alternative if valid\n",
    "            no_alt = True\n",
    "            if best_alt is not None:\n",
    "                self.add_alternative(best_alt)\n",
    "                no_alt = False\n",
    "            if best_alt_2 is not None:\n",
    "                self.add_alternative(best_alt_2)\n",
    "                no_alt = False\n",
    "            if no_alt:\n",
    "                self.model.log(f\"{self.unique_id} had no alternative.\")\n",
    "                return False\n",
    "        \n",
    "        if best_alt == self.path or best_alt_2 == self.path: # If the considered path is the same we considered, ignore.\n",
    "            self.model.log(f\"{self.unique_id} was already planning on to take this alternative.\")\n",
    "            return True\n",
    "        \n",
    "        # Diag or not\n",
    "        if best_alt_2 is not None:\n",
    "            best_alt = min([best_alt, best_alt_2], key=self.alternatives.get)\n",
    "\n",
    "        # NB: we first consider CF trajectory as a priority to avoid collision, however we may consider\n",
    "        # another threshold (e.g. 2*motivation) that fixes the tolerance of one to avoid non-imminent collision        \n",
    "\n",
    "        # Compute the value of worthiness to take this alternative compared to the envisioned cost of the other's\n",
    "        value = cost - self.alternatives[best_alt]\n",
    "        self.model.log(f\"An influence happened: {self.unique_id} processes a change of value {value}.\")\n",
    "        if value > self.motivation: # If the agent is satisfied with this alternative, it takes it. The cost should change.\n",
    "            self.model.log(f\"> {self.unique_id} reconsiders an alternative.\")\n",
    "            #self.alternatives[best_alt] = self.alternatives[min(self.alternatives, key=self.alternatives.get)] # We consider a cost similar to its best alternative as a measure of consideration.\n",
    "            self.alternatives[best_alt] = max(0, self.alternatives[best_alt] - min(abs(value), 3)) # The motivation may represent a cost adaptation to the others' offers, the less we win negotiations, the less we want to adapt ourselves\n",
    "            self.model.log(f\"{self.unique_id}'s alternatives: {self.alternatives}\")\n",
    "            new_path = self.select_path()\n",
    "            if new_path is not None and new_path != self.path:\n",
    "                self.model.log(f\"> {self.unique_id} takes another alternative.\")\n",
    "                self.path = new_path\n",
    "            self.influenced = True\n",
    "            return True\n",
    "        \n",
    "        self.model.log(f\"> {self.unique_id} agent refused the alternative.\")\n",
    "        # Otherwise the agent did not consider it\n",
    "        return False\n",
    "    \n",
    "    def select_path(self):\n",
    "        \"\"\"\n",
    "            Cognition part\n",
    "        \"\"\"\n",
    "        if len(self.alternatives) > 0:\n",
    "            bests = sorted(self.alternatives, key=self.alternatives.get)\n",
    "            best = bests[0]\n",
    "            #collision_free = list(filter(lambda p: is_walkable(self.model.grid, p[1], self.unique_id), bests))\n",
    "            #if len(collision_free) > 0:\n",
    "            #    best = min(collision_free)\n",
    "            #self.model.log(f\"{self.unique_id} has {len(self.alternatives)} alternatives: selected one with cost {self.alternatives[best]}\")\n",
    "            #self.model.log(f\"Alternatives of {self.unique_id}: {self.alternatives}\")\n",
    "            return best\n",
    "        return None\n",
    "    \n",
    "    def compute_set(self, obstacles=None):\n",
    "        \"\"\"\n",
    "            To enrich\n",
    "        \"\"\"\n",
    "        # TBR\n",
    "        path = self.find_path(obstacles=obstacles)\n",
    "        path_wait = (convert_coords(self.position),) + self.find_path(obstacles=obstacles)\n",
    "        #self.model.log(f\"{self.unique_id}'s path cost: {path_cost(self, path)}\")\n",
    "        #self.model.log(f\"{self.unique_id}'s path_wait cost: {path_cost(self, path_wait)}\")\n",
    "        if path is not None:\n",
    "            self.add_alternative(path)\n",
    "        if self.model.params[\"include_wait\"]:\n",
    "            if path_wait is not None:\n",
    "                self.add_alternative(path_wait)\n",
    "\n",
    "    def clear_set(self):\n",
    "        self.alternatives = {}\n",
    "    \n",
    "    def negotiate(self, neigh):\n",
    "        self.negotiating = True\n",
    "        self.colliding_point = collides(self.path, neigh.path)\n",
    "        if self.colliding_point is not None:\n",
    "            self.alert = True\n",
    "            self.bargainer = neigh\n",
    "            match self.model.params[\"negotiation\"]:\n",
    "                case \"wait_only\":\n",
    "                    if path_cost(self, self.path) < path_cost(self.bargainer, self.bargainer.path):\n",
    "                        self.wait = True\n",
    "                    self.bargainer.current_cost = path_cost(self.bargainer, self.bargainer.path)\n",
    "                    self.current_cost = path_cost(self, self.path)\n",
    "                case \"alt_or_wait\":\n",
    "                    alt_path = self.find_path(obstacles = [self.colliding_point], diag = True)\n",
    "                    alt_pathneigh = self.bargainer.find_path(obstacles = [self.colliding_point], diag = True)\n",
    "                    if alt_path is None or alt_pathneigh is None:\n",
    "                        if path_cost(self, self.path) > path_cost(self.bargainer, self.bargainer.path):\n",
    "                            self.wait = True\n",
    "                        else:\n",
    "                            self.bargainer.wait = True\n",
    "                    elif path_cost(self, alt_path) > path_cost(self.bargainer, alt_pathneigh):\n",
    "                        self.bargainer.path = alt_pathneigh\n",
    "                        self.bargainer.get_direction()\n",
    "                    else:\n",
    "                        self.path = alt_path\n",
    "                        self.get_direction() # update direction!!\n",
    "                    #TODO à mettre à jour\n",
    "                    self.current_cost = path_cost(self, alt_path)\n",
    "                    self.bargainer.current_cost = path_cost(self.bargainer, alt_pathneigh)\n",
    "\n",
    "    def add_alternative(self, path):\n",
    "        #self.model.log(f\"{self.unique_id}'s added path with cost: {path_cost(self, path)}\")\n",
    "        self.alternatives[path] = path_cost(self, path)\n",
    "\n",
    "    def init(self):\n",
    "        # First cognition step, to show trajectories.\n",
    "        self.compute_set()\n",
    "        self.path = self.select_path()\n",
    "        self.get_direction()\n",
    "    \n",
    "    def get_next_position(self):\n",
    "        \"\"\"\n",
    "            @returns: The next position given by the direction.\n",
    "        \"\"\"\n",
    "        return (self.position[0] + self.direction[0], self.position[1] + self.direction[1])\n",
    "    \n",
    "    def move(self, position):\n",
    "        \"\"\"\n",
    "            Attempt to move self to the given position.\n",
    "            \n",
    "            @returns: True if it moved, False otherwise\n",
    "        \"\"\"\n",
    "        if is_walkable(self.model.grid, position, self.unique_id):\n",
    "            self.position = position\n",
    "            self.model.grid.move_agent(self, self.position)\n",
    "            self.path = self.path[1:]\n",
    "\n",
    "            # Evaluation\n",
    "            self.global_path.append(list(self.position))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def step(self):\n",
    "        if not self.active:\n",
    "            return\n",
    "        \n",
    "        # Evaluation\n",
    "        self.tau += 1\n",
    "        \n",
    "        # Reset (in order)\n",
    "        self.negotiating = False\n",
    "        self.alert = False\n",
    "        self.colliding_point = None\n",
    "        self.influenced = False\n",
    "\n",
    "        # Cognition is supposed to be before motion, in order, however the initialisation step takes care of it.\n",
    "        \n",
    "        ### Move agent\n",
    "        \n",
    "        #self.position = (self.position[0] + .2, self.position[1] + .2)\n",
    "        alt = False\n",
    "        if not self.wait:\n",
    "            moved = False\n",
    "            position = self.get_next_position()\n",
    "            if self.direction is not None:\n",
    "                ## Check collision\n",
    "                moved = self.move(position)\n",
    "            # Otherwise wait or re-engage: to be discussed\n",
    "            # if an agent cannot move forward it is probably because there is some congestion, a negotiation process is quite meaningless here. Consider own alternative trajectory.\n",
    "            #\n",
    "            # This step is very important to discuss. In fact, the motion happens before the cognition part because of the initialization.\n",
    "            # As such, if the agent considers another alternative then it triggers the cognition part in advance and then moves. In order to respect the execution order the agent has to recompute its direction\n",
    "            # one more time to ensure the next move.\n",
    "            if not moved and not self.influenced:\n",
    "                self.model.log(f\"{self.unique_id} is blocked and not under influence, it considers another alternative.\")\n",
    "                mode = \"do_nothing\" # reflex?\n",
    "                match mode:\n",
    "                    case \"instant_alternative\":\n",
    "                        colliding_points = [position]\n",
    "                        for neigh in self.model.grid.get_neighbors(self.position, 2, False):\n",
    "                            if isinstance(neigh, Ped) and neigh.active:\n",
    "                                colliding_points.append(neigh.position)\n",
    "                        \n",
    "                        self.compute_set(obstacles=colliding_points)\n",
    "                        path = self.select_path()\n",
    "                        if path is not None:\n",
    "                            self.path = path\n",
    "                            self.get_direction()\n",
    "                            position = self.get_next_position()\n",
    "                            self.move(position)\n",
    "                            self.get_direction()\n",
    "                            alt = True\n",
    "                    #case _:\n",
    "                        # Wait by default\n",
    "        elif self.model.params[\"include_wait\"]:\n",
    "            # Waiting may be in the trajectory\n",
    "            self.path = self.path[1:]\n",
    "                        \n",
    "        \n",
    "        if self.position == self.objective:\n",
    "            self.active = False\n",
    "            self.model.grid.remove_agent(self)\n",
    "            return\n",
    "        \n",
    "        ### Cognition\n",
    "        match self.model.params[\"model\"]:\n",
    "            case \"first\":\n",
    "                self.compute_set()\n",
    "                self.path = self.select_path()\n",
    "                self.get_direction()\n",
    "            case \"second\":\n",
    "                self.clear_set() # is it fixed to compute_set? maybe\n",
    "                self.compute_set()\n",
    "                if not alt and not self.influenced:\n",
    "                    self.path = self.select_path()\n",
    "                    self.get_direction()\n",
    "\n",
    "        # Reset\n",
    "        self.wait = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "fb93385e-bebe-484a-804c-b689b6a963dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obstacle(mesa.Agent):\n",
    "    \n",
    "    def __init__(self, model, pos):\n",
    "        super().__init__(model)\n",
    "        self.position = pos\n",
    "\n",
    "    def step(self):\n",
    "        pass\n",
    "\n",
    "class Objective(mesa.Agent):\n",
    "    \n",
    "    def __init__(self, model, pos, id, number=-1, step=-1):\n",
    "        super().__init__(model)\n",
    "        self.position = pos\n",
    "        self.id = id\n",
    "        self.step = step\n",
    "        self.number = number\n",
    "\n",
    "    def step(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96cb69",
   "metadata": {},
   "source": [
    "## Global model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4543a3b-4b65-421a-b107-3c897787fa27",
   "metadata": {},
   "source": [
    "### Negotiation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "f7fff84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negotiation():\n",
    "    \"\"\"\n",
    "        A negotiation process happens between at least two agents, for now, in case of a collision.\n",
    "        A negotiation is the influence of a1 towards a2, a1 is trying to change the a2's preferences, with possible failure.\n",
    "\n",
    "        The following negotiation will happen:\n",
    "            a1 --->(influences) a2\n",
    "    \"\"\"\n",
    "    def __init__(self, model, a1, a2):\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "        self.model = model\n",
    "\n",
    "    \"\"\"\n",
    "        The negotiation process starts here, the result of such a process results in a failure for a1 or not.\n",
    "\n",
    "        @returns: False if a1 didn't suceed in its bargaining, True otherwise.\n",
    "    \"\"\"\n",
    "    def start(self):\n",
    "        result = False # No success for negotiation at beginning.\n",
    "\n",
    "        # Option\n",
    "        mode = \"self_trajectory\" # to change to self.model.params[\"influence_mode\"]\n",
    "\n",
    "        match mode:\n",
    "            case \"self_trajectory\":\n",
    "                \"\"\"\n",
    "                    This mode describes a1's influence as the proposal of its trajectory as an influence towards a2.\n",
    "                    a1's trajectory (i.e., path) is communicated along its cost to reveal (do we consider dishonesty?) its willingness/unwillingness to change path.\n",
    "                    a2 can then choose to either re-evaluate its best alternative collision-free trajectory's (w.r.t to a1's proposed path) cost, if it considers it worth it\n",
    "                    according to its tolerance threshold/motivation.\n",
    "                \"\"\"\n",
    "                a1 = self.a1\n",
    "                a2 = self.a2\n",
    "                # a1 proposes its trajectory to a2\n",
    "                ## a2 evaluates it and computes an alternative w.r.t. its threshold\n",
    "                self.model.log(f\"{a1.unique_id} negotiates with {a2.unique_id}\")\n",
    "                considered = a2.consider_alternative(a1.path, path_cost(a1, a1.path)) # TBI\n",
    "                if considered:\n",
    "                    a2.get_direction()\n",
    "                return considered\n",
    "            case _:\n",
    "                self.model.log(\"[Error] Unknown influence method. Abort influence.\")\n",
    "                return False\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ea887",
   "metadata": {},
   "source": [
    "### Vote process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "99f0b9ea-a37e-4f55-a01b-dca00108ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vote():\n",
    "    def __init__(self, model, agents):\n",
    "        self.model = model\n",
    "        self.neg_schedule = mesa.time.BaseScheduler(model, agents)\n",
    "        #for a in agents: for randomactivation\n",
    "        #    self.neg_schedule.add(a)\n",
    "        self.step = 0\n",
    "        self.Gamma = 5 # Option\n",
    "        self.conflicts = []\n",
    "    \n",
    "    def start(self):\n",
    "        self.model.log(\"------- Vote started -------\")\n",
    "        while self.step < self.Gamma:\n",
    "            self.model.log(f\"--- Iteration {self.step} ---\")\n",
    "            if not self.iter():\n",
    "                self.model.log(\"The vote ended prematurely, as there was no collision.\")\n",
    "                self.model.log(\"------- Vote ended -------\")# Clear alternatives\n",
    "                for a in self.neg_schedule.agents:\n",
    "                    a.clear_set()\n",
    "                return\n",
    "        # Check collisions\n",
    "        for conflict in self.conflicts:\n",
    "            # If there remain *IMMINENT* collisions then wait for some agents\n",
    "            a, neigh = conflict\n",
    "            # sort speed?? done here\n",
    "            # in truth, the colliding point may be updated even if paths were not updated, so it should be saved before\n",
    "            colliding_point = collides(a.path, neigh.path)\n",
    "            if len(a.path) > 1 and is_walkable(self.model.grid, a.path[1], a.unique_id) and a.path[1] != colliding_point:\n",
    "                continue\n",
    "            if len(neigh.path) > 1 and is_walkable(self.model.grid, neigh.path[1], neigh.unique_id) and neigh.path[1] != colliding_point:\n",
    "                continue\n",
    "            # Otherwise, imminent collision, wait for the one that has the most motivation\n",
    "            if a.motivation > neigh.motivation:\n",
    "                self.model.log(f\"> {a.unique_id} waited as negotiations didn't conclude.\")\n",
    "                a.wait = True\n",
    "            else:\n",
    "                self.model.log(f\"> {neigh.unique_id} waited as negotiations didn't conclude.\")\n",
    "                neigh.wait = True\n",
    "        # Clear alternatives and end negotiations\n",
    "        for a in self.neg_schedule.agents:\n",
    "            a.clear_set()\n",
    "        self.model.log(\"------- Vote ended -------\")\n",
    "    \n",
    "    def compute_welfare(self, collisions):\n",
    "        # Option\n",
    "        # param: mean\n",
    "        welfare = 0\n",
    "        for c in collisions:\n",
    "            a, neigh = c\n",
    "            welfare += abs(path_cost(a, a.path) - path_cost(neigh, neigh.path))\n",
    "        welfare /= len(collisions)\n",
    "        return welfare\n",
    "\n",
    "    def iter(self):\n",
    "\n",
    "        # I. Vote\n",
    "        # For now, each agent proposes its trajectory as its vote. If there is a collision, then negotiations continue.\n",
    "        ## To check on litterature\n",
    "        self.conflicts = [] # Pairs of agents that have conflicts between their respective paths\n",
    "        no_conflicts = []\n",
    "        DELTA = 2\n",
    "        for a in self.neg_schedule.agents:\n",
    "           for neigh in self.model.grid.get_neighbors(a.position, DELTA, False):\n",
    "                if isinstance(neigh, Ped) and neigh.active and not neigh.alert:\n",
    "                    if neigh.unique_id != a.unique_id:\n",
    "                        if collides(a.path, neigh.path) and (a, neigh) not in self.conflicts and (neigh, a) not in self.conflicts:\n",
    "                            self.model.log(f\"Conflict between {a.unique_id} and {neigh.unique_id}\")\n",
    "                            self.conflicts.append((a, neigh))\n",
    "                        else:\n",
    "                            no_conflicts.append((a, neigh))\n",
    "\n",
    "        ## If there is no conflict between agents, then negotiation ends.\n",
    "        # Option: This should be parameterized as agents may want to negotiate better trajectories even though there is no collision.\n",
    "        if self.conflicts == []:\n",
    "            self.model.log(\"No conflict\")\n",
    "            return False # End vote\n",
    "        \n",
    "        ## Compute welfare, all agents can get to know the welfare.\n",
    "        self.model.welfare = self.compute_welfare(self.conflicts)\n",
    "\n",
    "        # II. Influences\n",
    "        gain = .2 # Option\n",
    "        ## The agents influence themselves, e.g., try to impose their trajectory to others in order to change costs or votes.\n",
    "        for conflict in self.conflicts:\n",
    "            a, neigh = conflict\n",
    "            # Option: even if the agent is satisfied with the global welfare, if there remains a collision he can influence the other to take an advantaging trajectory for it.\n",
    "            # Satisfaction alone seems too independent and not relevant alone. We should consider satisfaction computed through the preferences to consider the relevancy of negotiations or not.\n",
    "            # The motivation is also considered through the cost function. Is it really different?\n",
    "            # In any case agents, here, should negotiate if there is a collision regardless of their satisfaction (reality constraint).\n",
    "            #if a.satisfaction < self.model.welfare:\n",
    "            # The satisfaction parameter should then play in collision-free trajectory agents.\n",
    "            a.negotiating = True\n",
    "            neigh.negotiating = True\n",
    "            success1 = Negotiation(self.model, a, neigh).start()\n",
    "            if not success1 and a.motivation - gain <= 0:\n",
    "                a.motivation /= 2\n",
    "            else:\n",
    "                a.motivation += gain if success1 else -gain\n",
    "            #a.motivation = max(.000001, a.motivation)\n",
    "\n",
    "            #if neigh.satisfaction < self.model.welfare:\n",
    "            success2 = Negotiation(self.model, neigh, a).start()\n",
    "            if not success2 and neigh.motivation - gain <= 0:\n",
    "                neigh.motivation /= 2\n",
    "            else:\n",
    "                neigh.motivation += gain if success2 else -gain\n",
    "            #neigh.motivation = max(.000001, neigh.motivation)\n",
    "        \n",
    "        # TO ADD\n",
    "        for no_conflict in no_conflicts:\n",
    "            continue\n",
    "        \n",
    "        self.step += 1\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ac1da",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "0ea1fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceModel(mesa.Model):\n",
    "\n",
    "    def __invert_y_coord(self, grid):\n",
    "        return grid[::-1]\n",
    "\n",
    "    def __init__(self, params, seed=None):\n",
    "        \"\"\"\n",
    "            Create a continuous space model with discretized time with the given map (2D array).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Model param\n",
    "        self.MAX_STEP = 50\n",
    "        self.step_value = 0\n",
    "\n",
    "        # Retrieve params\n",
    "        self.params = params\n",
    "        card = copy.deepcopy(params[\"map\"])\n",
    "\n",
    "        # Set seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        # Params\n",
    "        self.EXTRA_BORDER = 0\n",
    "        self.card = self.__invert_y_coord(card)\n",
    "        self.grid = mesa.space.ContinuousSpace(x_max = len(self.card[0]) + self.EXTRA_BORDER, y_max = len(self.card) + self.EXTRA_BORDER, torus = True, x_min=-self.EXTRA_BORDER, y_min=-self.EXTRA_BORDER)\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "        self.obstacles = []\n",
    "        self.welfare = 0 # Initial welfare\n",
    "        self.objectives = []\n",
    "\n",
    "        # Debug\n",
    "        self.msgs = []\n",
    "        \n",
    "        self.num_agents = 0\n",
    "        objective_id = 0\n",
    "        # Create agents\n",
    "        for y in range(len(self.card)):\n",
    "            for x in range(len(self.card[y])):\n",
    "                obj = self.card[y][x]\n",
    "                if obj == 1: # Agent\n",
    "                    a = Ped(self, (x, y))\n",
    "                    a.unique_id = self.num_agents\n",
    "                    self.num_agents += 1\n",
    "                    self.schedule.add(a)\n",
    "                    self.grid.place_agent(a, a.position)\n",
    "                elif obj == 2: # Obstacle\n",
    "                    o = Obstacle(self, (x, y))\n",
    "                    self.grid.place_agent(o, o.position)\n",
    "                    self.obstacles.append(o.position)\n",
    "                elif obj >= 3: # Multiple objectives possible\n",
    "                    o = Objective(self, (x, y), objective_id)\n",
    "                    objective_id += 1\n",
    "                    self.objectives.append(o)\n",
    "                    self.grid.place_agent(o, o.position)\n",
    "                # Otherwise empty\n",
    "        \n",
    "        # Update map for pathfinding\n",
    "        self.card = transform_grid(self.card)\n",
    "        \n",
    "        # Add objective for all agents\n",
    "        # For simplification purposes, let us assume agents take the farthest objective.\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, Ped):\n",
    "                dist = lambda o: np.linalg.norm(np.array(agent.position) - np.array(o.position))\n",
    "                agent.set_objective(max(self.objectives, key=dist))\n",
    "        \n",
    "        # Init agents\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, Ped):\n",
    "                agent.init()\n",
    "        \n",
    "        # First vote for instant-collision management\n",
    "        DELTA = 2 # attention at 100% here\n",
    "        for a in self.schedule.agents:\n",
    "            if not a.active or a.negotiating:\n",
    "                continue\n",
    "            neighbors = list(filter(lambda neigh: isinstance(neigh, Ped) and neigh.active and not neigh.negotiating, self.grid.get_neighbors(a.position, DELTA, False)))\n",
    "            neighbors.insert(0, a)\n",
    "            if len(neighbors) > 1:\n",
    "                #print(list(map(lambda a: f\"{a.unique_id} agent\", neighbors)))\n",
    "                vote = Vote(self, self.speed_sort(neighbors))\n",
    "                vote.start()\n",
    "    \n",
    "    def log(self, msg):\n",
    "        self.msgs.append(msg)\n",
    "    \n",
    "    def reset_log(self):\n",
    "        self.msgs = []\n",
    "    \n",
    "    def speed_sort(self, agents):\n",
    "        from functools import cmp_to_key\n",
    "        epsilon = .3\n",
    "        def compare_with_epsilon(a, b):\n",
    "            if abs(a - b) <= epsilon:\n",
    "                return np.random.choice([-1, 1])  # Treat as equal\n",
    "            return -1 if a < b else 1 \n",
    "        return sorted(agents, key=cmp_to_key(lambda i1, i2: compare_with_epsilon(i1.speed, i2.speed)))\n",
    "\n",
    "    def step(self):\n",
    "        if self.step_value >= self.MAX_STEP:\n",
    "            self.running = False\n",
    "            return\n",
    "\n",
    "        self.step_value += 1\n",
    "        \n",
    "        DELTA = 2 # attention at 100% here\n",
    "        # Make step all agents\n",
    "        self.schedule.step()\n",
    "        \n",
    "        match self.params[\"model\"]:\n",
    "            case \"first\":\n",
    "                for a in self.schedule.agents:\n",
    "                    if not a.active:\n",
    "                        continue\n",
    "\n",
    "                    ### Negotiation\n",
    "                    # Negotiation has to happen in all agent's loop after they *all* moved first in order to deal with updated positions. \n",
    "                    \n",
    "                    # self.position is discrete for now, however, we should consider comparing distances in float later\n",
    "                    for neigh in self.grid.get_neighbors(a.position, DELTA, False):\n",
    "                        if isinstance(neigh, Ped) and neigh.active and not neigh.alert:\n",
    "                            if neigh.unique_id != a.unique_id:\n",
    "                                a.negotiate(neigh)\n",
    "                                break\n",
    "            case \"second\":\n",
    "                # Doublons dans négotiations, regroupement des sous-groupes, la sélection des groupes de négotiation n'est pas triviale.\n",
    "                for a in self.schedule.agents:\n",
    "                    if not a.active or a.negotiating:\n",
    "                        continue\n",
    "                    neighbors = list(filter(lambda neigh: isinstance(neigh, Ped) and neigh.active and not neigh.negotiating, self.grid.get_neighbors(a.position, DELTA, False)))\n",
    "                    neighbors.insert(0, a)\n",
    "                    if len(neighbors) > 1:\n",
    "                        #print(list(map(lambda a: f\"{a.unique_id} agent\", neighbors)))\n",
    "                        vote = Vote(self, self.speed_sort(neighbors))\n",
    "                        vote.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee93d0",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "bb55773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"map\": map3,\n",
    "    \"negotiation\": \"alt_or_wait\", # wait_only\n",
    "    \"model\": \"second\",\n",
    "    \"include_wait\":False\n",
    "}\n",
    "model = SpaceModel(params)\n",
    "model.run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b007e1f",
   "metadata": {},
   "source": [
    "## Evaluation of CNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485629b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"map\": map7,\n",
    "    \"negotiation\": \"alt_or_wait\", # wait_only\n",
    "    \"model\": \"second\",\n",
    "    \"include_wait\":False\n",
    "}\n",
    "N = 1000\n",
    "results = [0, 0, []]\n",
    "for i in range(N):\n",
    "    model = SpaceModel(params)\n",
    "    model.run_model()\n",
    "    eval = get_evaluation(model.schedule.agents)\n",
    "    results[0] += eval[0]\n",
    "    results[1] += eval[1]\n",
    "    results[2].append(eval[1])\n",
    "print(\"Evaluation\")\n",
    "print(f\"[{round(results[0] / N, 2)}, {round(results[1] / N, 2)}, {round(np.std(results[2]), 2)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0257b",
   "metadata": {},
   "source": [
    "## Old visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbe774-d6c4-4c85-98c8-fdc8b7d03de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mesa.visualization import SolaraViz, make_plot_measure, make_space_matplotlib\n",
    "from mesa.experimental import JupyterViz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('hsv')\n",
    "\n",
    "def agent_portrayal(agent):\n",
    "    if isinstance(agent, Ped):\n",
    "        color = cmap(agent.unique_id*10)\n",
    "        if agent.alert:\n",
    "            color = cmap(agent.unique_id*10 - 10)\n",
    "        return {\n",
    "            \"color\": color,\n",
    "            \"size\": 50,\n",
    "        }\n",
    "    elif isinstance(agent, Obstacle):\n",
    "        return {\n",
    "            \"color\": \"tab:red\",\n",
    "            \"shape\": \"s\",\n",
    "            \"size\":100,\n",
    "        }\n",
    "    elif isinstance(agent, Objective):\n",
    "        return {\n",
    "            \"color\": \"tab:green\",\n",
    "            \"shape\": \"x\",\n",
    "            \"size\":80,\n",
    "        }\n",
    "\n",
    "model_params = {\n",
    "    \"map\": map2,\n",
    "    \"negotiation\": \"wait_only\",\n",
    "    \"include_wait\": False\n",
    "}\n",
    "\n",
    "# Create initial model instance\n",
    "model1 = SpaceModel(model_params)\n",
    "\n",
    "SpaceGraph = make_space_matplotlib(agent_portrayal)\n",
    "\n",
    "page = SolaraViz(\n",
    "    model1,\n",
    "    components=[SpaceGraph],\n",
    "    model_params=model_params,\n",
    "    name=\"Space Model\",\n",
    ")\n",
    "# This is required to render the visualization in the Jupyter notebook\n",
    "page\n",
    "\n",
    "# injecter des exemples\n",
    "# approfondir choix social et voir après les propriétés et thms du choix social, évaluer le modèle sur des exemples spéciqiues concrets qui marchent\n",
    "# écrire concis et ajouter formalisme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea784e-dc52-4856-9dca-c9f340fd4b78",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "2e02412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "def draw_obstacle(ax, x, y, size=0.3, corner_radius=0.1, color='red'):\n",
    "    rect = patches.FancyBboxPatch(\n",
    "        (x - size, y - size),  # Bottom-left corner\n",
    "        2 * size, 2 * size,    # Width and height\n",
    "        boxstyle=patches.BoxStyle(\"Round\", pad=corner_radius),\n",
    "        color=color\n",
    "    )\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "44c022b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifical agent class for CBS-MAPF's evaluation\n",
    "class CBSPed:\n",
    "    def __init__(self, objective):\n",
    "        self.objective = objective\n",
    "        self.optimal_path = []\n",
    "        self.global_path = []\n",
    "        self.tau = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "584ff704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a64fad952ed41b491d234d2ecb92c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.figure import Figure\n",
    "import matplotlib as mpl\n",
    "import solara\n",
    "\n",
    "# Components\n",
    "\n",
    "@solara.component\n",
    "def MarkdownWithColor(txts, color):\n",
    "    for txt in txts:\n",
    "        solara.Markdown(txt, style={\"color\": color})\n",
    "\n",
    "def normalize_to_8bit(rgb_normalized):\n",
    "    # Multiply each component by 255 and round to the nearest integer\n",
    "    return tuple(int(component * 255) for component in rgb_normalized)\n",
    "\n",
    "import webcolors\n",
    "\n",
    "# Function to find the closest color name\n",
    "def closest_color(requested_color):\n",
    "    min_colors = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - requested_color[0]) ** 2\n",
    "        gd = (g_c - requested_color[1]) ** 2\n",
    "        bd = (b_c - requested_color[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "def get_contrasted_color(rgb):\n",
    "    # Calculate brightness using the luminosity method\n",
    "    brightness = 0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]\n",
    "    \n",
    "    # Return black for light colors, white for dark colors\n",
    "    if brightness > 128:\n",
    "        return (0, 0, 0)  # Black\n",
    "    else:\n",
    "        return (255, 255, 255)  # White\n",
    "\n",
    "def get_complementary_color(rgb):\n",
    "    # Calculate the complementary color\n",
    "    return tuple(255 - component for component in rgb)\n",
    "\n",
    "# Main visualization\n",
    "\n",
    "step = solara.reactive(0)\n",
    "seed = solara.reactive(np.random.randint(0, 2<<32-1))\n",
    "debug = solara.reactive(True)\n",
    "jump = solara.reactive(0)\n",
    "log = solara.reactive(True)\n",
    "stats = solara.reactive(True)\n",
    "mode = solara.reactive(\"NBM\") # NBM: Negotiation Based Model or ad-hoc CBS-MAPF\n",
    "starts,goals,paths=[],[],[[]]\n",
    "grid = None\n",
    "msgs = []\n",
    "\n",
    "@solara.component\n",
    "def SpaceVisualization(clazz, params):\n",
    "    global starts, goals, paths, grid, msgs\n",
    "    \n",
    "    # Model tweak\n",
    "\n",
    "    def is_NBM():\n",
    "        return mode.value == \"NBM\" # Else CBS-MAPF\n",
    "\n",
    "    def get_disabled():\n",
    "        return not is_NBM()\n",
    "\n",
    "    def reset_model():\n",
    "        global grid, msgs\n",
    "        step.value = 0\n",
    "        if is_NBM():\n",
    "            set_model(clazz(params, seed=int(seed.value)))\n",
    "        else:\n",
    "            grid = None\n",
    "            msgs = []\n",
    "    \n",
    "    def set_mode(val):\n",
    "        print(\"Switching mode to\", val)\n",
    "        mode.value = val\n",
    "        reset_model()\n",
    "\n",
    "    # CBS-MAPF remasterized\n",
    "    def plan_cbs(mapx):\n",
    "        #### Utility functions\n",
    "        map_ = copy.deepcopy(mapx)\n",
    "        def get_agent_starts(mapp):\n",
    "            agts = []\n",
    "            agt_id = 1\n",
    "            for y in range(len(mapp)):\n",
    "                for x in range(len(mapp[y])):\n",
    "                    if mapp[y][x] == agt_id:\n",
    "                        agts.append((x, y))\n",
    "            return agts\n",
    "        def find_goals(mapp):\n",
    "            goals = []\n",
    "            goal_id = 3\n",
    "            for y in range(len(mapp)):\n",
    "                for x in range(len(mapp[y])):\n",
    "                    if mapp[y][x] >= goal_id:\n",
    "                        goals.append((x, y))\n",
    "            return goals\n",
    "        \n",
    "        # Call cbs-mapf to plan\n",
    "        starts = get_agent_starts(map_)\n",
    "        goals = find_goals(map_)\n",
    "        planner = Planner(map_)\n",
    "        paths = planner.plan(starts, goals, debug=False)\n",
    "        return starts, goals, paths\n",
    "    \n",
    "    # NBM: Negiotiation Based Model v1\n",
    "    \n",
    "    ### Utility\n",
    "    def format_path(path):\n",
    "        if path is None:\n",
    "            return \"[]\"\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        return list(map(cell, path))\n",
    "\n",
    "    ### Drawing\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.subplots()\n",
    "    #ax.grid(which='major', color='black', linestyle='--', linewidth=.2)\n",
    "    \n",
    "    ### Model\n",
    "    model, set_model = solara.use_state(clazz(params, seed=int(seed.value)))\n",
    "    \n",
    "    if is_NBM():\n",
    "        grid = model.grid\n",
    "        width = grid.width\n",
    "        height = grid.height\n",
    "    else:\n",
    "        if grid is None:\n",
    "            grid = copy.deepcopy(params[\"map\"])[::-1]\n",
    "        width = len(grid)\n",
    "        height = len(grid[0])\n",
    "\n",
    "    # Plot borders (temp fix for fixed grid)\n",
    "    c = .5\n",
    "    for (x, y) in [(-c, -c), (width+c, -c), (width+c, height+c), (-c, height+c)]:\n",
    "        ax.scatter(x, y, marker='+', c='blue')\n",
    "    \n",
    "    # Plot extended borders\n",
    "    border = 0\n",
    "    for (x, y) in [(-border, -border), (width+border, -border), (width+border, height+border), (-border, height+border)]:\n",
    "        ax.scatter(x, y, marker='+', c='black', linewidths=0)\n",
    "    \n",
    "    print(\"Restarting\\n\")\n",
    "    ## Init CBS-MAPF\n",
    "    if not is_NBM() and step.value == 0: # Start\n",
    "        grid = copy.deepcopy(params[\"map\"])[::-1]\n",
    "        #print(\"first grid\", grid)\n",
    "        map_value = maps.index(params[\"map\"]) + 1\n",
    "        msgs.append(f\"Init CBS-MAPF for map {map_value}\")\n",
    "        starts, goals, paths = plan_cbs(grid)\n",
    "\n",
    "        # Evaluation\n",
    "        peds = []\n",
    "        for i in range(len(starts)):\n",
    "            pathh = list(map(lambda x: (list(x)[0], list(x)[1]), paths[i]))\n",
    "            position = list(starts[i])\n",
    "            objective = list(pathh[-1])\n",
    "            ped = CBSPed(objective) # set objective\n",
    "            #print(\"global path:\", path)\n",
    "            ped.global_path = list(pathh)\n",
    "            \n",
    "            # A*\n",
    "            card = transform_grid(copy.deepcopy(params[\"map\"])[::-1])\n",
    "            gridd = Grid(height=len(card), width=len(card), matrix = card, inverse=False)\n",
    "            \n",
    "            grid_self_pos = convert_coords(position)\n",
    "\n",
    "            start = gridd.node(grid_self_pos[0], grid_self_pos[1])\n",
    "            end = gridd.node(objective[0], objective[1])\n",
    "\n",
    "            finder = AStarFinder(diagonal_movement = DiagonalMovement.always)\n",
    "            c_path, runs = finder.find_path(start, end, gridd)\n",
    "\n",
    "            cell = lambda c : (c.x, c.y)\n",
    "            opt_path = list(map(cell, c_path))\n",
    "\n",
    "            ped.optimal_path = opt_path\n",
    "            ped.tau = len(pathh)\n",
    "            peds.append(ped)\n",
    "\n",
    "        print(f\"CBS-MAPF evaluation for map {map_value}\\n\", get_evaluation(peds))\n",
    "\n",
    "    # Plot agents\n",
    "    cmap = mpl.colormaps['plasma']\n",
    "\n",
    "    obj_number = len(model.objectives) if is_NBM() else len(goals)\n",
    "    agents_number = len(model.schedule.agents) if is_NBM() else len(starts)\n",
    "\n",
    "    if obj_number > 1:\n",
    "        colors = cmap(np.linspace(0, 1, obj_number))\n",
    "    else:\n",
    "        # -- Take colors at regular intervals spanning the colormap.\n",
    "        colors = cmap(np.linspace(0, 1, agents_number))\n",
    "    \n",
    "    ## NBM visualization\n",
    "    if is_NBM():\n",
    "        for a in model.agents:\n",
    "            if not isinstance(a, Ped):\n",
    "                continue ## We may skip this by removing other non-agents, however they may remain useful to consider neighbor obstacles.\n",
    "            if not a.active:\n",
    "                continue\n",
    "            \n",
    "            col = None\n",
    "            if len(model.objectives) > 1:\n",
    "                col = colors[a.objective_obj.id]\n",
    "            else:\n",
    "                col = colors[a.unique_id]\n",
    "            \n",
    "            x, y = a.position\n",
    "            if debug.value:\n",
    "                # -- Trajectory\n",
    "                if len(a.path) > 1:\n",
    "                    xs, ys = zip(*a.path[:min(3, len(a.path))])\n",
    "                    c = col\n",
    "                    # Add continuous arrow at the end of the last segment\n",
    "                    ax.annotate('', xy=(xs[-1], ys[-1]), xytext=(xs[-2], ys[-2]), arrowprops=dict(edgecolor=c, facecolor=c, linewidth=1.2, width=1.2, headwidth=7, headlength=4.5, alpha=.25, zorder=0), zorder=0)\n",
    "                    #ax.quiver(xs[-2], ys[-2], xs[-1] - xs[-2], ys[-1] - ys[-2], angles='xy', scale_units='xy', scale=1, color='b', linewidth=2)\n",
    "                    # Plot segment just after\n",
    "                    ax.plot(xs, ys, linestyle=':', color=c, linewidth=2.8, zorder=1, alpha=1)\n",
    "\n",
    "                # -- Speed\n",
    "                ax.arrow(x, y, a.direction[0] * a.speed, a.direction[1] * a.speed, width = 0.03, color='green', alpha=.5, zorder=1)\n",
    "            # -- Agent\n",
    "            ax.scatter(x, y, linewidths=12, alpha=1, color=col, zorder=2)\n",
    "            #if debug.value:\n",
    "                # -- Virtual obstacle\n",
    "                #if a.negotiating and a.colliding_point is not None:\n",
    "                    #xs, ys = a.colliding_point \n",
    "                    #ax.scatter(xs, ys, linewidths=18, alpha=.5, c='purple')\n",
    "            # -- Id\n",
    "            ax.annotate(a.unique_id, (x+.1, y+.1), c='black', zorder=2)\n",
    "        \n",
    "        # Plot obstacles\n",
    "        for (x, y) in model.obstacles:\n",
    "            #ax.fill([x-.5, x-.5, x+.5, x+.5], [y-.5, y+.5, y+.5, y-.5], c='red')\n",
    "            #ax.scatter(x, y, c='red', linewidths=8, marker='s')\n",
    "            draw_obstacle(ax, x, y)\n",
    "            \n",
    "        # Plot objective (to change)\n",
    "        for obj in model.objectives:\n",
    "            x, y = obj.position\n",
    "            ax.scatter(x, y, c='green', marker='x', linewidths=10)\n",
    "    ## CBS-MAPF visualization\n",
    "    else:\n",
    "        #if len(model.objectives) > 1:\n",
    "        #    col = colors[i]\n",
    "        #else:\n",
    "        #    col = colors[a.unique_id]\n",
    "        ### Plot agents\n",
    "        i = 0\n",
    "        for agent_path in paths:\n",
    "            if step.value >= len(agent_path):\n",
    "                continue\n",
    "            x, y = agent_path[step.value]\n",
    "            c = colors[i]\n",
    "            ax.scatter(x, y, linewidths=12, alpha=1, color=c, zorder=2)\n",
    "            i += 1\n",
    "            ### Plot directions\n",
    "            if len(agent_path) - step.value > 1:\n",
    "                xs, ys = zip(*agent_path[step.value:min(step.value+3, len(agent_path))])\n",
    "                # Add continuous arrow at the end of the last segment\n",
    "                ax.annotate('', xy=(xs[-1], ys[-1]), xytext=(xs[-2], ys[-2]), arrowprops=dict(edgecolor=c, facecolor=c, linewidth=1.2, width=1.2, headwidth=7, headlength=4.5, alpha=.25, zorder=0), zorder=0)\n",
    "                #ax.quiver(xs[-2], ys[-2], xs[-1] - xs[-2], ys[-1] - ys[-2], angles='xy', scale_units='xy', scale=1, color='b', linewidth=2)\n",
    "                # Plot segment just after\n",
    "                ax.plot(xs, ys, linestyle=':', color=c, linewidth=2.8, zorder=1, alpha=1)\n",
    "\n",
    "        if i == 0:\n",
    "            msgs.append(\"Found no paths\")\n",
    "        ### Plot goals\n",
    "        for (x, y) in goals:\n",
    "            ax.scatter(x, y, c='green', marker='x', linewidths=10)\n",
    "        ### Plot obstacles\n",
    "        for y in range(len(grid)):\n",
    "            for x in range(len(grid[y])):\n",
    "                if grid[y][x] == 2:\n",
    "                    ax.scatter(x, y, c='red', linewidths=8, marker='s')\n",
    "\n",
    "    # Plot grid - common to two models\n",
    "    # Manually set major and minor ticks to ensure spacing is correct\n",
    "    ax.set_xticks(np.arange(-border-2, width+border+2, 1), minor=False)\n",
    "    ax.set_yticks(np.arange(-border-2, height+border+2, 1), minor=False)\n",
    "    ax.set_xticks(np.arange(-border-2, width+border+2, .5), minor=True)\n",
    "    ax.set_yticks(np.arange(-border-2, height+border+2, .5), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"gray\", linestyle='-', linewidth=.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ### Model UI\n",
    "    def model_update():\n",
    "        if is_NBM():\n",
    "            if jump.value == 0:\n",
    "                model.step()\n",
    "                step.value += 1\n",
    "            else:\n",
    "                for i in range(int(jump.value)):\n",
    "                    if i == int(jump.value) - 1:\n",
    "                        model.reset_log()\n",
    "                    model.step()\n",
    "                step.value += int(jump.value)\n",
    "                jump.value = 0\n",
    "            # Plot agents\n",
    "            for a in model.agents:\n",
    "                ax.scatter(a.position[0], a.position[1], linewidths=10)\n",
    "        else:\n",
    "            step.value += 1 # Jump later\n",
    "\n",
    "    def set_random_seed():\n",
    "        rng = np.random.default_rng()\n",
    "        seed.set(rng.integers(0, 2<<32-1))\n",
    "        reset_model()\n",
    "\n",
    "    def set_map(map):\n",
    "        params[\"map\"] = maps[int(map.split(\" \")[-1])-1]\n",
    "        reset_model()\n",
    "    \n",
    "    def set_debug():\n",
    "        debug.value = not debug.value\n",
    "    \n",
    "    def set_log():\n",
    "        log.value = not log.value\n",
    "    \n",
    "    def set_stats():\n",
    "        stats.value = not stats.value\n",
    "    \n",
    "    msg_error = \"Undefined\"\n",
    "    \n",
    "    with solara.VBox() as main:\n",
    "        with solara.Columns():\n",
    "            if is_NBM():\n",
    "                solara.FigureMatplotlib(fig, dependencies=[ax, model.agents])\n",
    "            else:\n",
    "                solara.FigureMatplotlib(fig, dependencies=[ax])\n",
    "                \n",
    "            # UI\n",
    "            with solara.VBox():\n",
    "                solara.Button(label=f\"Step {step}\", on_click=model_update)\n",
    "                solara.InputText(\"Jump\", value=jump)\n",
    "                solara.Button(label=f\"Reset (seed: {seed.value})\", on_click=reset_model)\n",
    "                with solara.Row(gap=\"0px\", justify=\"space-evenly\"):\n",
    "                    solara.Button(label=f\"Debug ({debug.value})\", on_click=set_debug)\n",
    "                    solara.Button(label=f\"Log ({log.value})\", on_click=set_log)\n",
    "                    solara.Button(label=f\"Agents' stats ({stats.value})\", on_click=set_stats)\n",
    "                with solara.Row():\n",
    "                    solara.Button(\"Random\", on_click=set_random_seed, disabled=get_disabled())\n",
    "                    solara.InputText(\"Set Seed\", value=seed, disabled=get_disabled())\n",
    "                with solara.Columns():\n",
    "                    solara.Select(label=\"Map\",\n",
    "                                values=list(map(lambda x: f\"Map {x}\", list(range(1, len(maps)+1)))),\n",
    "                                value=\"Map 2\",\n",
    "                                on_value=set_map)\n",
    "                    solara.Select(label=\"Model\",\n",
    "                                values=[\"NBM\", \"ad-hoc CBS-MAPF\"],\n",
    "                                value=\"NBM\",\n",
    "                                on_value=set_mode)\n",
    "                solara.Text(f\"Global welfare: {model.welfare if is_NBM() else msg_error}\")\n",
    "                solara.Text(f\"Negotiating mode (first model only): {params['negotiation'] if is_NBM() else msg_error}\")\n",
    "                solara.Text(f\"Model: {params['model'] if is_NBM() else msg_error}\")\n",
    "                if log.value:\n",
    "                    MarkdownWithColor([\"## Log\"], \"cyan\")\n",
    "                    solara.Card(\n",
    "                                children=[MarkdownWithColor([\"<br>\".join(model.msgs if is_NBM() else msgs)], \"cyan\")],\n",
    "                                style={\"maxHeight\": \"400px\", \"overflow\": \"auto\", \"border\": \"2px solid black\", \"padding\": \"0px\"}    \n",
    "                            )\n",
    "                    # MarkdownWithColor([\"-------------- [LOG] --------------\", \"<br>\".join(model.msgs)], \"cyan\")\n",
    "        if stats.value and is_NBM():\n",
    "            with solara.Columns():\n",
    "                # Main\n",
    "                for a in model.agents:\n",
    "                    if not isinstance(a, Ped):\n",
    "                        continue\n",
    "                    col = None\n",
    "                    if len(model.objectives) > 1:\n",
    "                        col = colors[a.objective_obj.id]\n",
    "                    else:\n",
    "                        col = colors[a.unique_id]\n",
    "                    col = normalize_to_8bit(tuple(col[:3]))\n",
    "                    title = f\"\"\"<h1 style=\"text-shadow: 1px 1px 1px black;color: {closest_color(col)};\">Agent {a.unique_id}:</h1>\"\"\"\n",
    "                    txt = f\"\"\"<h3 style=\"line-height:1.5;background-color: rgba(0, 100, 120, 0.5); filter: blur(0.25px); color:white\">\n",
    "                    <ul>\n",
    "                    <li> Real position: {a.position} | Cell position: {convert_coords(a.position)} </li>\n",
    "                    <li> Direction: {a.direction} </li>\n",
    "                    <li> Speed: {round(a.speed, 3)} </li>\n",
    "                    <li> Objective: {a.objective} </li>\n",
    "                    <li> Path: {a.path} </li>\n",
    "                    <li> Negotiating: {a.negotiating} </li>\n",
    "                    <li> Alert: {a.alert} </li>\n",
    "                    <li> Envisioned cost: {a.current_cost} </li>\n",
    "                    <li> Motivation: {round(a.motivation, 3)} </li>\n",
    "                    <li> Satisfaction: {round(a.satisfaction, 3)} </li>\n",
    "                    <li> Influenced : {a.influenced} </li>\n",
    "                    <li> Wait : {a.wait} </li>\n",
    "                    </h3>\n",
    "                    \"\"\"\n",
    "                    MarkdownWithColor([title, txt], \"black\")\n",
    "                \n",
    "            model.reset_log()\n",
    "    return main\n",
    "\n",
    "params = {\n",
    "    \"map\": map2,\n",
    "    \"negotiation\": \"alt_or_wait\", # wait_only\n",
    "    \"model\": \"second\",\n",
    "    \"include_wait\":False\n",
    "}\n",
    "\n",
    "## Seeds\n",
    "# blocking: 695489792\n",
    "# 3436061971\n",
    "# 5 lost: 597585348 -> the cost should take into account the direction change\n",
    "# 1767546085: 6 lost it\n",
    "# 2686383803: 5 is dumb\n",
    "# Map 2: 3138802159 1 lost it\n",
    "# Cf. blocking cases https://www.youtube.com/watch?v=c3ITUMLz6KI\n",
    "# Map 6: interblocking 3068477672, 4232108719\n",
    "# 2556336118, 1905464572 : cool\n",
    "# 257805472 check map 3\n",
    "# 2402532377 : map 5 blocking\n",
    "\"\"\"\n",
    "Les négotiations de façon plus locales dé-fluidifient l'ensemble, à l'instar de la physique.\n",
    "L'ajout de la possibilité d'attente et de l'attente forcée des négotiations impliquent une dynamique\n",
    "de simulation naturelle entre agents comme files d'attente ou attente globale afin de laisser les décisions\n",
    "à ceux qui sont le plus libre.\n",
    "\n",
    "Point clé sur les négotiations :\n",
    "il n'y a pas de priorité dans l'ordre des négotiations entamées pour une meilleure gestion des collisions *IMMINENTES*\n",
    "effet file-indienne (par Emma) donné, i.e., interblocage. Effet de coûts statu-quo par multiples négotiations et persévérance dans les négotiations entre agents\n",
    "\n",
    "- scheduler nesté dépendant des vitesses TO DO mildly done\n",
    "- wait seulement dans imminent collision OK\n",
    "- voir la résolution de conflits par négotiation de sous-trajectoires ou trajectoires globales TO DO\n",
    "- affiner les multiples négotiations par le facteur attention et priorité de collisions/difficultés (à quantifier par mot et att cf. rapport)  TO DO\n",
    "\"\"\"\n",
    "# - Validation d'un certain nombre de propositions à travers certains scénarios, examples et démonstrations.\n",
    "# e.g. c'est celui avec le moins de contrainte qui doit/peut débloquer la situation\n",
    "# ^ section expérimentale où on commente les paramètres, notamment avec la fonction de coût, étudier les relations TO DO\n",
    "# e.g. l'importance dans l'algo de la motivation et son évolution avec le lien au nombre de steps (comparaison FS)\n",
    "# e.g. importance de fonction de coût et modélisation à différents niveaux (attente notamment) ainsi qu'évolution par màj\n",
    "# e.g. exemples propagation motivations par blocage et fonction de coût\n",
    "# e.g. votes locaux (propagation ici)\n",
    "# e.g. priorité et inertie ?\n",
    "# - montrer exécution schedulers avec algo pour voir la dynamique et biais TO DO\n",
    "# > sequential move\n",
    "# - interprétation motivation (à expliquer) comme jeu coopératif avec volonté altruiste TO DO\n",
    "# - CBS MAPF\n",
    "# - site web Olivier Thèse\n",
    "# - parler propagation questions ouvertes TO DO\n",
    "# - préparer présentation 15-20 minutes, modèle +move, algo ILLUSTRés, hypothèses choix, démonstrations (expés insistance). aprèm\n",
    "# FS 8 directions ici, sous-section comparaisons TO DO\n",
    "# fix pseudo-random\n",
    "# specify algo of dynamism\n",
    "# map 3 : 692016961\n",
    "# honest vote\n",
    "SpaceVisualization(SpaceModel, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65872d",
   "metadata": {},
   "source": [
    "# Social Force model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960de16",
   "metadata": {},
   "source": [
    "## Agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "0ff1644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SFPed(mesa.Agent):\n",
    "    def __init__(self, model, pos):\n",
    "        super().__init__(model)\n",
    "\n",
    "        # Params\n",
    "        self.model = model\n",
    "        self.active = True\n",
    "\n",
    "        # Attributes\n",
    "        self.position = np.array(pos, dtype=np.float64)\n",
    "        self.velocity = np.array((0, 0), dtype=np.float64)\n",
    "        self.desired_vel = np.array((1, 1), dtype=np.float64)\n",
    "        self.objective = None\n",
    "        self.radius = 3\n",
    "        self.mass = 10\n",
    "        self.speed = .1\n",
    "        self.direction = np.array((0, 0))\n",
    "        self.last_dir = np.array((0, 0))\n",
    "        # others?\n",
    "\n",
    "        # Evaluation\n",
    "        self.tau = 0 # Time taken until goal is reached: Tau_i\n",
    "        self.global_path = [] # Final path to be registered: T_i^+\n",
    "        self.optimal_path = None # Optimal computed A* path with no other agents\n",
    "    \n",
    "    def init(self):\n",
    "        self.desired_vel = self.compute_desired_velocity()\n",
    "        self.velocity = self.get_next_velocity()\n",
    "        self.direction = self.get_direction()\n",
    "    \n",
    "    def set_objectives(self, objs):\n",
    "        self.objectives = objs\n",
    "\n",
    "        # Evaluation, the function set_objectives is only called once in anycase\n",
    "        # The last objective is the final one\n",
    "        self.final_objective = self.objectives[-1].position\n",
    "        \n",
    "        # Transform card\n",
    "        card = transform_grid(self.model.card)\n",
    "        # Compute A*\n",
    "        grid = Grid(height=len(card), width=len(card[0]), matrix = card, inverse=False)\n",
    "        grid_self_pos = convert_coords(self.position)\n",
    "\n",
    "        start = grid.node(grid_self_pos[0], grid_self_pos[1])\n",
    "        end = grid.node(self.final_objective[0], self.final_objective[1])\n",
    "\n",
    "        finder = AStarFinder(diagonal_movement = DiagonalMovement.always)\n",
    "        path, runs = finder.find_path(start, end, grid)\n",
    "\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        path = list(map(cell, path))\n",
    "        self.optimal_path = path\n",
    "\n",
    "        # Set objective\n",
    "\n",
    "        self.__update_objective()\n",
    "    \n",
    "    def __update_objective(self):\n",
    "        if len(self.objectives) <= 0:\n",
    "            return False # Already set\n",
    "        \n",
    "        # Set objective\n",
    "        obj = self.objectives[0]\n",
    "        self.objective_obj = obj\n",
    "        self.objective = np.array(obj.position, dtype=np.float64)\n",
    "        \n",
    "        # Determine next objective\n",
    "        dist = np.linalg.norm(self.position - self.objective)\n",
    "        eps = 1.5\n",
    "        if dist <= eps: # If the objective has been reached\n",
    "            self.objectives = self.objectives[1:]\n",
    "            #print(\"^_ reached objective\")\n",
    "        \n",
    "        return True # Remaining objectives\n",
    "    \n",
    "    def is_walkable(grid, position, unique_id):\n",
    "        pos = position\n",
    "        for a in grid.get_neighbors(pos, .1, True):\n",
    "            if a.unique_id != unique_id and not isinstance(a, Objective):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def compute_desired_velocity(self):\n",
    "        direction_to_objective = self.objective - self.position\n",
    "        # Normalize\n",
    "        distance_to_objective = np.linalg.norm(direction_to_objective)\n",
    "        \n",
    "        if distance_to_objective > 0:\n",
    "            desired_velocity = self.speed * direction_to_objective / distance_to_objective\n",
    "        else:\n",
    "            desired_velocity = np.zeros_like(self.position)\n",
    "        \n",
    "        return desired_velocity\n",
    "    \n",
    "    # Forces\n",
    "    def compute_ped_repulsion_force(self):\n",
    "        agents = self.model.schedule.agents\n",
    "        F = np.zeros_like(self.position)\n",
    "        for agent in agents:\n",
    "            if isinstance(agent, SFPed):\n",
    "                if agent.unique_id != self.unique_id:\n",
    "                    distance = np.linalg.norm(self.position - agent.position)\n",
    "                    if distance < self.radius:\n",
    "                        repulsion_force = (self.position - agent.position) / (distance**2)\n",
    "                        F += repulsion_force\n",
    "        return F\n",
    "    \n",
    "    def compute_obs_repulsion_force(self):\n",
    "        F = np.zeros_like(self.position)\n",
    "        for obs in self.model.obstacles:\n",
    "            obstacle = np.array(obs, dtype=np.float64)\n",
    "            distance = np.linalg.norm(self.position - obstacle)\n",
    "            if distance < self.radius:\n",
    "                obstacle_force = (self.position - obstacle) / (distance**2)\n",
    "                F += obstacle_force\n",
    "        return F\n",
    "        \n",
    "    def compute_objective_force(self, tau):\n",
    "        return (1/tau) * (self.objective - self.position)\n",
    "    \n",
    "    def compute_velocity_force(self):\n",
    "        return self.mass * (self.desired_vel - self.velocity)\n",
    "\n",
    "    def compute_forces(self):\n",
    "        tau = 1\n",
    "        return self.compute_ped_repulsion_force() + self.compute_obs_repulsion_force() + self.compute_objective_force(tau) + self.compute_velocity_force()\n",
    "\n",
    "    def get_next_velocity(self):\n",
    "        # t + delta t velocity, i.e., t + 1 in discretized time\n",
    "        return self.velocity + self.compute_forces() / self.mass\n",
    "\n",
    "    def get_direction(self):\n",
    "        end = self.velocity\n",
    "        data = end\n",
    "\n",
    "        if not (data == 0).all():\n",
    "            data = data / np.linalg.norm(data)\n",
    "        \n",
    "        def round_up(x):\n",
    "            sign = 1\n",
    "            if x < 0:\n",
    "                sign = -1\n",
    "            val = abs(x)\n",
    "            if val < self.model.threshold:\n",
    "                val = 0\n",
    "            elif not np.isnan(val):\n",
    "                val = math.ceil(val)\n",
    "            else:\n",
    "                return 0\n",
    "            return min(1, val) * sign\n",
    "        \n",
    "        return list(map(round_up, data)) # ceil may be too strong, a threshold can be required\n",
    "        #return end\n",
    "\n",
    "    def get_next_position(self, dir):\n",
    "        # at t + 1\n",
    "        return self.position + dir\n",
    "\n",
    "    def move(self, dir, pos):\n",
    "        self.direction = dir\n",
    "        self.position = pos\n",
    "        self.model.grid.move_agent(self, self.position)\n",
    "\n",
    "        # Evaluation\n",
    "        self.global_path.append(list(self.position))\n",
    "\n",
    "    def step(self):\n",
    "        # End\n",
    "        if not self.active:\n",
    "            return\n",
    "        \n",
    "        # Move as init takes care of first step of cognition\n",
    "        dir = self.direction\n",
    "        pos = self.get_next_position(dir)\n",
    "        if is_walkable(self.model.grid, convert_coords(pos), self.unique_id):\n",
    "            self.move(dir, pos)\n",
    "            self.last_dir = dir\n",
    "        else:\n",
    "            # Check if it is possible to slide\n",
    "            # y first\n",
    "            dir_y = dir[:]\n",
    "            dir_y[0] = 0\n",
    "            pos_y = self.get_next_position(dir_y)\n",
    "            dir_x = dir[:]\n",
    "            dir_x[1] = 0\n",
    "            pos_x = self.get_next_position(dir_x)\n",
    "            if is_walkable(self.model.grid, pos_y, self.unique_id):\n",
    "                self.move(dir_y, pos_y)\n",
    "                self.last_dir = dir_y\n",
    "            elif is_walkable(self.model.grid, pos_x, self.unique_id):\n",
    "                self.move(dir_x, pos_x)\n",
    "                self.last_dir = dir_x\n",
    "\n",
    "        if not self.__update_objective(): # If there is no remaining objective\n",
    "            # End\n",
    "            if np.array_equal(np.array(convert_coords(self.position), dtype=np.float64), self.objective):\n",
    "                self.active = False\n",
    "                self.model.grid.remove_agent(self)\n",
    "                return\n",
    "        \n",
    "        # Think\n",
    "        self.velocity = self.get_next_velocity()\n",
    "        self.direction = self.get_direction()\n",
    "\n",
    "        # Evaluation\n",
    "        self.tau += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f214d1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "df473c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFModel(mesa.Model):\n",
    "    def __init__(self, params, threshold=.01, seed=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Model\n",
    "        self.step_value = 0\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # Retrieve params\n",
    "        self.params = params\n",
    "        card = copy.deepcopy(params[\"map\"])[::-1]\n",
    "        self.card = card\n",
    "\n",
    "        # Logs\n",
    "        self.msgs = []\n",
    "\n",
    "        # Set seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Map and scheduler\n",
    "        self.EXTRA_BORDER = 0\n",
    "        self.grid = mesa.space.ContinuousSpace(x_max = len(card[0]) + self.EXTRA_BORDER, y_max = len(card) + self.EXTRA_BORDER, torus = True, x_min=-self.EXTRA_BORDER, y_min=-self.EXTRA_BORDER)\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "        self.obstacles = []\n",
    "        self.objectives = []\n",
    "\n",
    "        # Others\n",
    "        self.num_agents = 0\n",
    "        objective_id = 0\n",
    "\n",
    "        # Create agents\n",
    "        sub_objectives = dict()\n",
    "        for y in range(len(card)):\n",
    "            for x in range(len(card[y])):\n",
    "                obj = card[y][x]\n",
    "                if obj == 1: # Agent\n",
    "                    a = SFPed(self, (x, y))\n",
    "                    a.unique_id = self.num_agents\n",
    "                    self.num_agents += 1\n",
    "                    self.schedule.add(a)\n",
    "                    self.grid.place_agent(a, a.position)\n",
    "                elif obj == 2: # Obstacle\n",
    "                    o1 = Obstacle(self, (x, y))\n",
    "                    self.grid.place_agent(o1, o1.position)\n",
    "                    self.obstacles.append(o1.position)\n",
    "                elif obj >= 3: # In discretized SFM, we implement successive intermediate objectives.\n",
    "                    meta_info = list(map(int, list(str(obj)))) # Objective 31 refers as Objective 1 (number 3) and first step (1)\n",
    "                    #print(\"--- meta info:\", meta_info)\n",
    "                    obj_number, obj_step = meta_info[0], meta_info[1]\n",
    "                    o = Objective(self, (x, y), objective_id, number=obj_number, step=obj_step)\n",
    "                    objective_id += 1\n",
    "                    sub_objectives.setdefault(obj_number, list()).append(o)\n",
    "                    self.objectives.append(o)\n",
    "                    self.grid.place_agent(o, o.position)\n",
    "                # Otherwise empty\n",
    "        \n",
    "        # Sort sequences of objectives\n",
    "        for k in sub_objectives.keys():\n",
    "            sub_objectives[k] = sorted(sub_objectives[k], key=lambda o: o.step)\n",
    "        #print(\"--- sub_objectives:\", sub_objectives)\n",
    "        \n",
    "        # Add objectives for all agents\n",
    "        # For simplification purposes, let us assume agents take the same sequence of objectives.\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, SFPed):\n",
    "                dist = lambda o: np.linalg.norm(np.array(agent.position) - np.array(o.position))\n",
    "                objective = max(self.objectives, key=dist)\n",
    "                # Assign the corresponding sequence\n",
    "                agent.set_objectives(sub_objectives[objective.number])\n",
    "        \n",
    "        # Init agents\n",
    "        for agent in self.schedule.agents:\n",
    "            if isinstance(agent, SFPed):\n",
    "                agent.init()\n",
    "    \n",
    "    def reset_log(self):\n",
    "        self.msgs = []\n",
    "    \n",
    "    def step(self):\n",
    "        if self.step_value >= 50: # MAX STEP\n",
    "            self.running = False\n",
    "            return\n",
    "        self.schedule.step()\n",
    "        self.step_value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7deff7c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_params = {\"map\": map7}\n",
    "N = 1000\n",
    "for threshold in [.01, .05, .15, .3, .45, .5, .6, .65, .7, .8, .9]:\n",
    "    results = [0, 0, []]\n",
    "    for i in range(N):\n",
    "        model = SFModel(sf_params, threshold)\n",
    "        model.run_model()\n",
    "        eval = get_evaluation(model.schedule.agents)\n",
    "        results[0] += eval[0]\n",
    "        results[1] += eval[1]\n",
    "        results[2].append(eval[1])\n",
    "    print(f\"Evaluation (threshold={threshold})\")\n",
    "    print(f\"[{round(results[0] / N, 2)}, {round(results[1] / N, 2)}, {round(np.std(results[2]), 2)}]\")\n",
    "# Dans l'article\n",
    "# justifier fondement choix social\n",
    "# souligner l'approche sociale avec les négociations\n",
    "# parler de l'évaluation avec les différents thresholds\n",
    "# rappeler de la différence online et offline avec planificateur de l'un et de l'autre algorithme dynamique avec une volonté sociale\n",
    "# rappeler les implémentations ad-hoc, sans passer trop de temps sur les détails, qui permettent un premier jet de comparaison\n",
    "# souligner que le modèle est sujet à encore des améliorations et ici cela fonde les bases de CNM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a092f80",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "b2c759c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c15df0850ab499680231c322ec188d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.figure import Figure\n",
    "import matplotlib as mpl\n",
    "import solara\n",
    "import time\n",
    "\n",
    "# Components\n",
    "\n",
    "@solara.component\n",
    "def MarkdownWithColor(txts, color):\n",
    "    for txt in txts:\n",
    "        solara.Markdown(txt, style={\"color\": color})\n",
    "\n",
    "def normalize_to_8bit(rgb_normalized):\n",
    "    # Multiply each component by 255 and round to the nearest integer\n",
    "    return tuple(int(component * 255) for component in rgb_normalized)\n",
    "\n",
    "import webcolors\n",
    "\n",
    "# Function to find the closest color name\n",
    "def closest_color(requested_color):\n",
    "    min_colors = {}\n",
    "    for name in webcolors.names(\"css3\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - requested_color[0]) ** 2\n",
    "        gd = (g_c - requested_color[1]) ** 2\n",
    "        bd = (b_c - requested_color[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "def get_contrasted_color(rgb):\n",
    "    # Calculate brightness using the luminosity method\n",
    "    brightness = 0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]\n",
    "    \n",
    "    # Return black for light colors, white for dark colors\n",
    "    if brightness > 128:\n",
    "        return (0, 0, 0)  # Black\n",
    "    else:\n",
    "        return (255, 255, 255)  # White\n",
    "\n",
    "def get_complementary_color(rgb):\n",
    "    # Calculate the complementary color\n",
    "    return tuple(255 - component for component in rgb)\n",
    "\n",
    "# Main visualization\n",
    "\n",
    "step = solara.reactive(0)\n",
    "seed = solara.reactive(np.random.randint(0, 2<<32-1))\n",
    "debug = solara.reactive(True)\n",
    "jump = solara.reactive(0)\n",
    "log = solara.reactive(True)\n",
    "stats = solara.reactive(True)\n",
    "run = solara.reactive(False)\n",
    "result = None\n",
    "\n",
    "@solara.component\n",
    "def SpaceVisualization(clazz, params):\n",
    "    \n",
    "    ### Utility\n",
    "    def format_path(path):\n",
    "        if path is None:\n",
    "            return \"[]\"\n",
    "        cell = lambda c : (c.x, c.y)\n",
    "        return list(map(cell, path))\n",
    "    \n",
    "    ### Model\n",
    "    model, set_model = solara.use_state(clazz(params, seed=int(seed.value)))\n",
    "\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.subplots()\n",
    "    #ax.grid(which='major', color='black', linestyle='--', linewidth=.2)\n",
    "    grid = model.grid\n",
    "\n",
    "    # Plot borders (temp fix for fixed grid)\n",
    "    c = .5\n",
    "    for (x, y) in [(-c, -c), (grid.width+c, -c), (grid.width+c, grid.height+c), (-c, grid.height+c)]:\n",
    "        ax.scatter(x, y, marker='+', c='blue')\n",
    "    \n",
    "    # Plot extended borders\n",
    "    border = 0\n",
    "    for (x, y) in [(-border, -border), (grid.width+border, -border), (grid.width+border, grid.height+border), (-border, grid.height+border)]:\n",
    "        ax.scatter(x, y, marker='+', c='black', linewidths=0)\n",
    "\n",
    "    # Plot agents\n",
    "    cmap = mpl.colormaps['plasma']\n",
    "\n",
    "    if len(model.objectives) > 1:\n",
    "        colors = cmap(np.linspace(0, 1, len(model.objectives)))\n",
    "    else:\n",
    "        # -- Take colors at regular intervals spanning the colormap.\n",
    "        colors = cmap(np.linspace(0, 1, len(model.schedule.agents)))\n",
    "    \n",
    "    for a in model.agents:\n",
    "        if not isinstance(a, SFPed):\n",
    "            continue ## We may skip this by removing other non-agents, however they may remain useful to consider neighbor obstacles.\n",
    "        if not a.active:\n",
    "            continue\n",
    "        \n",
    "        col = None\n",
    "        if len(model.objectives) > 1:\n",
    "            col = colors[a.objective_obj.id]\n",
    "        else:\n",
    "            col = colors[a.unique_id]\n",
    "        \n",
    "        x, y = a.position\n",
    "        if debug.value:\n",
    "            # -- Trajectory\n",
    "            xs, ys = (a.position[0], a.position[0] + a.direction[0]), (a.position[1], a.position[1] + a.direction[1])\n",
    "            c = col\n",
    "            # Add continuous arrow at the end of the last segment\n",
    "            #ax.annotate('', xy=(xs[-1], ys[-1]), xytext=(xs[-2], ys[-2]), arrowprops=dict(edgecolor=c, facecolor=c, linewidth=1.2, width=1.2, headwidth=7, headlength=4.5, alpha=.25, zorder=0), zorder=0)\n",
    "            ax.quiver(xs[-2], ys[-2], xs[-1] - xs[-2], ys[-1] - ys[-2], angles='xy', scale_units='xy', scale=1, color=c, linewidth=.1)\n",
    "            # Plot segment just after\n",
    "            #ax.plot(xs, ys, linestyle=':', color=c, linewidth=2.8, zorder=1, alpha=1)\n",
    "\n",
    "            # -- Speed\n",
    "            #ax.arrow(x, y, a.direction[0] * a.speed, a.direction[1] * a.speed, width = 0.03, color='green', alpha=.5, zorder=1)\n",
    "        # -- Agent\n",
    "        ax.scatter(x, y, linewidths=12, alpha=1, color=col, zorder=2)\n",
    "        # -- Id\n",
    "        ax.annotate(a.unique_id, (x+.1, y+.1), c='black', zorder=2)\n",
    "    \n",
    "    # Plot obstacles\n",
    "    gap = .4\n",
    "    for (x, y) in model.obstacles:\n",
    "        #ax.fill([x-gap, x-gap, x+gap, x+gap], [y-gap, y+gap, y+gap, y-gap], c='red')\n",
    "        #ax.scatter(x, y, c='red', linewidths=8, marker='s')\n",
    "        draw_obstacle(ax, x, y)\n",
    "        \n",
    "    # Plot objective (to change)\n",
    "    for obj in model.objectives:\n",
    "        x, y = obj.position\n",
    "        ax.scatter(x, y, c='green', marker='x', linewidths=10)\n",
    "    \n",
    "    # Plot grid\n",
    "    # Manually set major and minor ticks to ensure spacing is correct\n",
    "    ax.set_xticks(np.arange(-border-2, grid.width+border+2, 1), minor=False)\n",
    "    ax.set_yticks(np.arange(-border-2, grid.height+border+2, 1), minor=False)\n",
    "    ax.set_xticks(np.arange(-border-2, grid.width+border+2, .5), minor=True)\n",
    "    ax.set_yticks(np.arange(-border-2, grid.height+border+2, .5), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"gray\", linestyle='-', linewidth=.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ### Model UI\n",
    "    def model_update():\n",
    "        if jump.value == 0:\n",
    "            model.step()\n",
    "            step.value += 1\n",
    "        else:\n",
    "            for i in range(int(jump.value)):\n",
    "                if i == int(jump.value) - 1:\n",
    "                    model.reset_log()\n",
    "                model.step()\n",
    "            step.value += int(jump.value)\n",
    "            jump.value = 0\n",
    "        # Plot agents\n",
    "        for a in model.agents:\n",
    "            ax.scatter(a.position[0], a.position[1], linewidths=10)\n",
    "\n",
    "    def reset_model():\n",
    "        step.value = 0\n",
    "        set_model(clazz(params, seed=int(seed.value)))\n",
    "\n",
    "    def set_random_seed():\n",
    "        rng = np.random.default_rng()\n",
    "        seed.set(rng.integers(0, 2<<32-1))\n",
    "        reset_model()\n",
    "\n",
    "    def set_map(map):\n",
    "        params[\"map\"] = copy.deepcopy(maps[int(map.split(\" \")[-1])-1])\n",
    "        reset_model()\n",
    "    \n",
    "    def set_debug():\n",
    "        debug.value = not debug.value\n",
    "    \n",
    "    def set_log():\n",
    "        log.value = not log.value\n",
    "    \n",
    "    def set_stats():\n",
    "        stats.value = not stats.value\n",
    "\n",
    "    def set_run():\n",
    "        import threading\n",
    "        run.value = not run.value\n",
    "        if run.value:\n",
    "            threading.Thread(target=run_simulation, args=(True, model.agents.set)).start()\n",
    "            #result: solara.Result[bool] = solara.use_thread(run_simulation, dependencies=[])  # noqa: SH102\n",
    "            #for i in range(50):\n",
    "            #    model.step()\n",
    "            #    time.sleep(.1)\n",
    "        elif result is not None:\n",
    "            #result.cancel()\n",
    "            pass\n",
    "    \n",
    "    def run_simulation(f, set_agents):\n",
    "        for i in range(50):\n",
    "            model.step()\n",
    "            set_agents(model.agents)\n",
    "            time.sleep(.1)\n",
    "\n",
    "    with solara.VBox() as main:\n",
    "        with solara.Columns():\n",
    "            solara.FigureMatplotlib(fig, dependencies=[ax, model.agents])\n",
    "                \n",
    "            # UI\n",
    "            with solara.VBox():\n",
    "                solara.Button(label=f\"Step {step}\", on_click=model_update)\n",
    "                solara.InputText(\"Jump\", value=jump)\n",
    "                solara.Button(label=f\"Reset (seed: {seed.value})\", on_click=reset_model)\n",
    "                with solara.Row(gap=\"0px\", justify=\"space-evenly\"):\n",
    "                    solara.Button(label=\"Run\" if not run.value else \"Stop\", on_click=set_run)\n",
    "                    solara.Button(label=f\"Debug ({debug.value})\", on_click=set_debug)\n",
    "                    solara.Button(label=f\"Log ({log.value})\", on_click=set_log)\n",
    "                    solara.Button(label=f\"Agents' stats ({stats.value})\", on_click=set_stats)\n",
    "                with solara.Row():\n",
    "                    solara.Button(\"Random\", on_click=set_random_seed)\n",
    "                    solara.InputText(\"Set Seed\", value=seed)\n",
    "                with solara.Columns():\n",
    "                    solara.Select(label=\"Map\",\n",
    "                                  values=list(map(lambda x: f\"Map {x}\", list(range(1, len(maps)+1)))),\n",
    "                                  value=\"Map 2\",\n",
    "                                  on_value=set_map)\n",
    "                #solara.Text(f\"Global welfare: {model.welfare}\")\n",
    "                #solara.Text(f\"Negotiating mode (first model only): {params['negotiation']}\")\n",
    "                #solara.Text(f\"Model: {params['model']}\")\n",
    "                if log.value:\n",
    "                    MarkdownWithColor([\"## Log\"], \"cyan\")\n",
    "                    solara.Card(\n",
    "                                children=[MarkdownWithColor([\"<br>\".join(model.msgs)], \"cyan\")],\n",
    "                                style={\"maxHeight\": \"400px\", \"overflow\": \"auto\", \"border\": \"2px solid black\", \"padding\": \"0px\"}    \n",
    "                            )\n",
    "                    # MarkdownWithColor([\"-------------- [LOG] --------------\", \"<br>\".join(model.msgs)], \"cyan\")\n",
    "        if stats.value:\n",
    "            with solara.Columns():\n",
    "                # Main\n",
    "                for a in model.agents:\n",
    "                    if not isinstance(a, SFPed):\n",
    "                        continue\n",
    "                    col = None\n",
    "                    if len(model.objectives) > 1:\n",
    "                        col = colors[a.objective_obj.id]\n",
    "                    else:\n",
    "                        col = colors[a.unique_id]\n",
    "                    col = normalize_to_8bit(tuple(col[:3]))\n",
    "                    title = f\"\"\"<h1 style=\"text-shadow: 1px 1px 1px black;color: {closest_color(col)};\">Agent {a.unique_id}:</h1>\"\"\"\n",
    "                    txt = f\"\"\"<h3 style=\"line-height:1.5;background-color: rgba(0, 100, 120, 0.5); filter: blur(0.25px); color:white\">\n",
    "                    <ul>\n",
    "                    <li> Real position: {a.position} | Cell position: {convert_coords(a.position)} </li>\n",
    "                    <li> Direction: {a.direction} </li>\n",
    "                    <li> Previous dir: {a.direction} </li>\n",
    "                    <li> Velocity: {a.velocity} </li>\n",
    "                    <li> Objective: {a.objective} </li>\n",
    "                    </h3>\n",
    "                    \"\"\"\n",
    "                    MarkdownWithColor([title, txt], \"black\")\n",
    "            \n",
    "        model.reset_log()\n",
    "\n",
    "    return main\n",
    "\n",
    "sf_params = {\n",
    "    \"map\": map3,\n",
    "}\n",
    "\n",
    "SpaceVisualization(SFModel, sf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1e0c8",
   "metadata": {},
   "source": [
    "# Experiments results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    \"CNM\": [[1.0, 0.0, 0.0], [1.0, 0.12, 0.22], [1.0, 0.36, 0.44], [1.0, 5.2, 0.31], [0.99, 4.13, 0.92], [0.98, 4.3, 2.98], [1.0, 2.13, 0.42]],\n",
    "    \"ad-hoc SFM\": [[0.83, 2.0, 0.0], [0.51, 4.57, 8.36], [0.84, 0.24, 0.25], [0.54, 14.76, 3.86], [0.52, 17.95, 3.88], [0.93, 25.03, 2.89], [0.97, 20.77, 3.24]],\n",
    "    \"ad-hoc CBS-MAPF\": [[1.0, 0.0, 0.0], [1.0, 1.0, 1.41], [0.95, 0.5, 0.71], [1.0, 1.0, 0.71], [-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]\n",
    "}\n",
    "\n",
    "maps = [f\"Map {i}\" for i in range(1, 8)]\n",
    "\n",
    "# Première figure : dist pour les 3 algorithmes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'legend.fontsize': 12,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12\n",
    "})\n",
    "colors = ['#1b9e77', '#d95f02', '#54278f']\n",
    "linestyles = ['-', '--', ':']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i, (algo, values) in enumerate(data.items()):\n",
    "    metrique1 = [v[0] for v in values]\n",
    "    index = metrique1.index(-1) if -1 in metrique1 else len(maps)\n",
    "    plt.plot(maps[:index], metrique1[:index], label=algo, marker='o', linestyle=linestyles[i], color=colors[i])\n",
    "\n",
    "plt.xlabel('Maps')\n",
    "plt.ylabel('dist(A)')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.title('Comparaison de dist(A) pour les 3 algorithmes')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Deuxième figure : wait et equi avec barres d'erreur\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i, (algo, values) in enumerate(data.items()):\n",
    "    metrique2 = [v[1] for v in values]\n",
    "    std_dev = [v[2] for v in values]\n",
    "    index = metrique2.index(-1) if -1 in metrique2 else len(maps)\n",
    "    plt.errorbar(maps[:index], metrique2[:index], yerr=std_dev[:index], label=algo, marker='o', linestyle=linestyles[i], color=colors[i], capsize=10, capthick=2, elinewidth=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Maps')\n",
    "plt.ylabel('wait(A)')\n",
    "plt.title(\"Comparaison de wait(A) avec écart-type pour les 3 algorithmes\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f728f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f1f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orproject1",
   "language": "python",
   "name": "orproject1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
